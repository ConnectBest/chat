{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c23138a",
   "metadata": {},
   "source": [
    "# ğŸ§  Agent Short-Term Memory with MongoDB\n",
    "\n",
    "This notebook demonstrates how to implement **short-term memory** for the ConnectBest chat agent using MongoDB.\n",
    "\n",
    "## Memory Architecture\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                     Memory Collection                        â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚  {                                                           â”‚\n",
    "â”‚    \"_id\": ObjectId,                                          â”‚\n",
    "â”‚    \"session_id\": \"user_123_1701388800\",                     â”‚\n",
    "â”‚    \"user_id\": \"user_123\",                                    â”‚\n",
    "â”‚    \"messages\": [                                             â”‚\n",
    "â”‚      {\"role\": \"user\", \"content\": \"...\", \"ts\": ...},         â”‚\n",
    "â”‚      {\"role\": \"assistant\", \"content\": \"...\", \"ts\": ...}     â”‚\n",
    "â”‚    ],                                                        â”‚\n",
    "â”‚    \"context\": {...},  # Extracted entities, preferences     â”‚\n",
    "â”‚    \"created_at\": datetime,                                   â”‚\n",
    "â”‚    \"updated_at\": datetime,                                   â”‚\n",
    "â”‚    \"expires_at\": datetime  # TTL for auto-cleanup           â”‚\n",
    "â”‚  }                                                           â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "## Features\n",
    "1. **Session-based memory** - Conversations grouped by session\n",
    "2. **TTL expiration** - Auto-cleanup of old sessions (e.g., 24 hours)\n",
    "3. **Context extraction** - Remember user preferences and entities\n",
    "4. **Sliding window** - Keep last N messages to manage token limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b42421f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Packages installed!\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "import subprocess\n",
    "subprocess.run([\"pip\", \"install\", \"-q\", \"pymongo\", \"python-dotenv\"], check=True)\n",
    "print(\"âœ… Packages installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37fda6a",
   "metadata": {},
   "source": [
    "## 1. Connect to MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4917196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Connected to MongoDB: connectbest_chat\n",
      "ğŸ“š Collections: ['channel_members', 'messages', 'message_embeddings', 'reactions', 'files', 'channels', 'threads', 'message_files', 'users']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Optional, List, Dict, Any\n",
    "from pymongo import MongoClient, ASCENDING, DESCENDING\n",
    "from pymongo.server_api import ServerApi\n",
    "from pymongo.collection import Collection\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "\n",
    "# Add parent directory to path for imports\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))\n",
    "\n",
    "# Load environment variables from app's .env\n",
    "load_dotenv(\"../app/api/tools/.env\")\n",
    "\n",
    "# Connect to MongoDB using MONGO_URI (same as the app uses)\n",
    "MONGO_URI = os.getenv(\"MONGO_URI\")\n",
    "DATABASE_NAME = os.getenv(\"MONGO_DATABASE\", \"connectbest_chat\")\n",
    "\n",
    "if not MONGO_URI:\n",
    "    raise ValueError(\"âŒ MONGO_URI not found in .env file! Please set it.\")\n",
    "\n",
    "client = MongoClient(MONGO_URI, server_api=ServerApi('1'))\n",
    "db = client[DATABASE_NAME]\n",
    "\n",
    "# Test connection\n",
    "client.admin.command('ping')\n",
    "print(f\"âœ… Connected to MongoDB: {DATABASE_NAME}\")\n",
    "print(f\"ğŸ“š Collections: {db.list_collection_names()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce322227",
   "metadata": {},
   "source": [
    "## 2. Define the Memory Manager Class\n",
    "\n",
    "This class handles all memory operations:\n",
    "- **Session management** - Create/retrieve sessions by user ID\n",
    "- **Message storage** - Store user/assistant messages with timestamps  \n",
    "- **Context extraction** - Remember entities, preferences mentioned\n",
    "- **Window management** - Keep last N messages to manage token limits\n",
    "- **TTL expiration** - Auto-cleanup old sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da33bba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Memory indexes created\n",
      "ğŸ“Š Memory Stats: {'total_sessions': 0, 'active_sessions': 0, 'expired_sessions': 0, 'collection': 'agent_memory'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_113537/1377085574.py:249: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  \"expires_at\": {\"$gt\": datetime.utcnow()}\n"
     ]
    }
   ],
   "source": [
    "class AgentMemory:\n",
    "    \"\"\"\n",
    "    Short-term memory manager for the ConnectBest agent.\n",
    "    \n",
    "    Stores conversation history in MongoDB with:\n",
    "    - Session-based grouping (conversations expire after TTL)\n",
    "    - Sliding window (last N messages)\n",
    "    - Context extraction (entities, preferences)\n",
    "    - TTL-based expiration (auto-cleanup)\n",
    "    \"\"\"\n",
    "    \n",
    "    COLLECTION_NAME = \"agent_memory\"\n",
    "    DEFAULT_TTL_HOURS = 24  # Sessions expire after 24 hours\n",
    "    DEFAULT_MAX_MESSAGES = 20  # Keep last 20 messages per session\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        db, \n",
    "        ttl_hours: int = DEFAULT_TTL_HOURS,\n",
    "        max_messages: int = DEFAULT_MAX_MESSAGES\n",
    "    ):\n",
    "        self.db = db\n",
    "        self.collection: Collection = db[self.COLLECTION_NAME]\n",
    "        self.ttl_hours = ttl_hours\n",
    "        self.max_messages = max_messages\n",
    "        \n",
    "        # Ensure indexes exist\n",
    "        self._setup_indexes()\n",
    "    \n",
    "    def _setup_indexes(self):\n",
    "        \"\"\"Create necessary indexes for efficient queries.\"\"\"\n",
    "        # Index for fast user lookup\n",
    "        self.collection.create_index([(\"user_id\", ASCENDING)])\n",
    "        \n",
    "        # Index for session lookup\n",
    "        self.collection.create_index([(\"session_id\", ASCENDING)], unique=True)\n",
    "        \n",
    "        # TTL index for auto-expiration\n",
    "        # MongoDB will automatically delete documents when expires_at < now\n",
    "        self.collection.create_index(\n",
    "            [(\"expires_at\", ASCENDING)],\n",
    "            expireAfterSeconds=0  # Delete when expires_at time is reached\n",
    "        )\n",
    "        \n",
    "        print(\"âœ… Memory indexes created\")\n",
    "    \n",
    "    def _generate_session_id(self, user_id: str) -> str:\n",
    "        \"\"\"Generate a unique session ID for a user.\"\"\"\n",
    "        # Session ID includes timestamp to create new sessions over time\n",
    "        timestamp = int(datetime.utcnow().timestamp())\n",
    "        return f\"{user_id}_{timestamp}\"\n",
    "    \n",
    "    def get_or_create_session(self, user_id: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Get the active session for a user, or create a new one.\n",
    "        \n",
    "        A session is considered \"active\" if:\n",
    "        - It exists and hasn't expired\n",
    "        - It was updated within the TTL window\n",
    "        \"\"\"\n",
    "        now = datetime.utcnow()\n",
    "        cutoff = now - timedelta(hours=self.ttl_hours)\n",
    "        \n",
    "        # Find active session\n",
    "        session = self.collection.find_one({\n",
    "            \"user_id\": user_id,\n",
    "            \"updated_at\": {\"$gt\": cutoff}\n",
    "        }, sort=[(\"updated_at\", DESCENDING)])\n",
    "        \n",
    "        if session:\n",
    "            return session\n",
    "        \n",
    "        # Create new session\n",
    "        session_id = self._generate_session_id(user_id)\n",
    "        new_session = {\n",
    "            \"session_id\": session_id,\n",
    "            \"user_id\": user_id,\n",
    "            \"messages\": [],\n",
    "            \"context\": {\n",
    "                \"entities\": [],      # Named entities mentioned\n",
    "                \"preferences\": {},   # User preferences\n",
    "                \"topics\": [],        # Topics discussed\n",
    "            },\n",
    "            \"created_at\": now,\n",
    "            \"updated_at\": now,\n",
    "            \"expires_at\": now + timedelta(hours=self.ttl_hours)\n",
    "        }\n",
    "        \n",
    "        self.collection.insert_one(new_session)\n",
    "        print(f\"ğŸ“ Created new session: {session_id}\")\n",
    "        return new_session\n",
    "    \n",
    "    def add_message(\n",
    "        self, \n",
    "        user_id: str, \n",
    "        role: str, \n",
    "        content: str,\n",
    "        metadata: Optional[Dict] = None\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Add a message to the user's active session.\n",
    "        \n",
    "        Args:\n",
    "            user_id: The user's ID\n",
    "            role: \"user\" or \"assistant\"\n",
    "            content: The message content\n",
    "            metadata: Optional metadata (tool calls, etc.)\n",
    "        \n",
    "        Returns:\n",
    "            The updated session document\n",
    "        \"\"\"\n",
    "        now = datetime.utcnow()\n",
    "        \n",
    "        message = {\n",
    "            \"role\": role,\n",
    "            \"content\": content,\n",
    "            \"timestamp\": now,\n",
    "            \"metadata\": metadata or {}\n",
    "        }\n",
    "        \n",
    "        # Get or create session\n",
    "        session = self.get_or_create_session(user_id)\n",
    "        \n",
    "        # Update session with new message\n",
    "        result = self.collection.update_one(\n",
    "            {\"session_id\": session[\"session_id\"]},\n",
    "            {\n",
    "                \"$push\": {\n",
    "                    \"messages\": {\n",
    "                        \"$each\": [message],\n",
    "                        \"$slice\": -self.max_messages  # Keep only last N messages\n",
    "                    }\n",
    "                },\n",
    "                \"$set\": {\n",
    "                    \"updated_at\": now,\n",
    "                    \"expires_at\": now + timedelta(hours=self.ttl_hours)  # Extend TTL\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        return self.get_session(session[\"session_id\"])\n",
    "    \n",
    "    def get_session(self, session_id: str) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"Get a session by ID.\"\"\"\n",
    "        return self.collection.find_one({\"session_id\": session_id})\n",
    "    \n",
    "    def get_conversation_history(\n",
    "        self, \n",
    "        user_id: str, \n",
    "        limit: Optional[int] = None\n",
    "    ) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Get the conversation history for a user.\n",
    "        \n",
    "        Args:\n",
    "            user_id: The user's ID\n",
    "            limit: Optional limit on messages to return\n",
    "        \n",
    "        Returns:\n",
    "            List of messages in chronological order\n",
    "        \"\"\"\n",
    "        session = self.get_or_create_session(user_id)\n",
    "        messages = session.get(\"messages\", [])\n",
    "        \n",
    "        if limit:\n",
    "            messages = messages[-limit:]\n",
    "        \n",
    "        return messages\n",
    "    \n",
    "    def get_formatted_history(\n",
    "        self, \n",
    "        user_id: str, \n",
    "        limit: Optional[int] = None\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Get conversation history formatted for LLM context.\n",
    "        \n",
    "        Returns a string like:\n",
    "        User: What channels are there?\n",
    "        Assistant: I found 5 channels...\n",
    "        User: Tell me about #general\n",
    "        \"\"\"\n",
    "        messages = self.get_conversation_history(user_id, limit)\n",
    "        \n",
    "        formatted = []\n",
    "        for msg in messages:\n",
    "            role = \"User\" if msg[\"role\"] == \"user\" else \"Assistant\"\n",
    "            formatted.append(f\"{role}: {msg['content']}\")\n",
    "        \n",
    "        return \"\\n\".join(formatted)\n",
    "    \n",
    "    def update_context(\n",
    "        self, \n",
    "        user_id: str, \n",
    "        entities: Optional[List[str]] = None,\n",
    "        preferences: Optional[Dict] = None,\n",
    "        topics: Optional[List[str]] = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Update the context for a user's session.\n",
    "        \n",
    "        This stores extracted information like:\n",
    "        - Entities: \"Alice\", \"Project X\", \"#general\"\n",
    "        - Preferences: {\"timezone\": \"PST\", \"preferred_channel\": \"general\"}\n",
    "        - Topics: [\"meeting scheduling\", \"project updates\"]\n",
    "        \"\"\"\n",
    "        session = self.get_or_create_session(user_id)\n",
    "        \n",
    "        update = {\"$set\": {\"updated_at\": datetime.utcnow()}}\n",
    "        \n",
    "        if entities:\n",
    "            update[\"$addToSet\"] = {\"context.entities\": {\"$each\": entities}}\n",
    "        \n",
    "        if preferences:\n",
    "            for key, value in preferences.items():\n",
    "                update.setdefault(\"$set\", {})\n",
    "                update[\"$set\"][f\"context.preferences.{key}\"] = value\n",
    "        \n",
    "        if topics:\n",
    "            update.setdefault(\"$addToSet\", {})\n",
    "            update[\"$addToSet\"][\"context.topics\"] = {\"$each\": topics}\n",
    "        \n",
    "        self.collection.update_one(\n",
    "            {\"session_id\": session[\"session_id\"]},\n",
    "            update\n",
    "        )\n",
    "    \n",
    "    def get_context(self, user_id: str) -> Dict[str, Any]:\n",
    "        \"\"\"Get the stored context for a user.\"\"\"\n",
    "        session = self.get_or_create_session(user_id)\n",
    "        return session.get(\"context\", {})\n",
    "    \n",
    "    def clear_session(self, user_id: str) -> bool:\n",
    "        \"\"\"Clear/delete a user's current session.\"\"\"\n",
    "        result = self.collection.delete_many({\"user_id\": user_id})\n",
    "        return result.deleted_count > 0\n",
    "    \n",
    "    def get_all_sessions(self, user_id: str) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Get all sessions for a user (for debugging).\"\"\"\n",
    "        return list(self.collection.find(\n",
    "            {\"user_id\": user_id},\n",
    "            sort=[(\"created_at\", DESCENDING)]\n",
    "        ))\n",
    "    \n",
    "    def get_stats(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get memory statistics.\"\"\"\n",
    "        total_sessions = self.collection.count_documents({})\n",
    "        active_sessions = self.collection.count_documents({\n",
    "            \"expires_at\": {\"$gt\": datetime.utcnow()}\n",
    "        })\n",
    "        \n",
    "        return {\n",
    "            \"total_sessions\": total_sessions,\n",
    "            \"active_sessions\": active_sessions,\n",
    "            \"expired_sessions\": total_sessions - active_sessions,\n",
    "            \"collection\": self.COLLECTION_NAME\n",
    "        }\n",
    "\n",
    "# Create memory instance\n",
    "memory = AgentMemory(db)\n",
    "print(f\"ğŸ“Š Memory Stats: {memory.get_stats()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f133cc09",
   "metadata": {},
   "source": [
    "## 3. Demo: Simulate a Conversation\n",
    "\n",
    "Let's simulate a multi-turn conversation to see how memory works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93869dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§¹ Cleared existing sessions\n",
      "\n",
      "============================================================\n",
      "ğŸ“¨ Turn 1: User asks about channels\n",
      "============================================================\n",
      "ğŸ“ Created new session: demo_user_123_1764658451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_113537/1377085574.py:112: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  now = datetime.utcnow()\n",
      "/tmp/ipykernel_113537/1377085574.py:61: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  now = datetime.utcnow()\n",
      "/tmp/ipykernel_113537/1377085574.py:50: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  timestamp = int(datetime.utcnow().timestamp())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“œ Conversation History:\n",
      "User: What channels are available?\n",
      "Assistant: I found 5 channels: #general, #engineering, #design, #marketing, and #random.\n"
     ]
    }
   ],
   "source": [
    "# Simulate a user ID (this would come from Slack in production)\n",
    "TEST_USER_ID = \"demo_user_123\"\n",
    "\n",
    "# Clear any existing session for clean demo\n",
    "memory.clear_session(TEST_USER_ID)\n",
    "print(\"ğŸ§¹ Cleared existing sessions\")\n",
    "\n",
    "# Simulate conversation turn 1\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“¨ Turn 1: User asks about channels\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "memory.add_message(TEST_USER_ID, \"user\", \"What channels are available?\")\n",
    "memory.add_message(\n",
    "    TEST_USER_ID, \n",
    "    \"assistant\", \n",
    "    \"I found 5 channels: #general, #engineering, #design, #marketing, and #random.\",\n",
    "    metadata={\"tool_used\": \"list_channels\", \"channels_found\": 5}\n",
    ")\n",
    "\n",
    "# Show current history\n",
    "print(\"\\nğŸ“œ Conversation History:\")\n",
    "print(memory.get_formatted_history(TEST_USER_ID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "999edd90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ğŸ“¨ Turn 2: User asks follow-up about a specific channel\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_113537/1377085574.py:112: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  now = datetime.utcnow()\n",
      "/tmp/ipykernel_113537/1377085574.py:61: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  now = datetime.utcnow()\n",
      "/tmp/ipykernel_113537/1377085574.py:209: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  update = {\"$set\": {\"updated_at\": datetime.utcnow()}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“œ Full Conversation History:\n",
      "User: What channels are available?\n",
      "Assistant: I found 5 channels: #general, #engineering, #design, #marketing, and #random.\n",
      "User: Tell me more about #engineering\n",
      "Assistant: The #engineering channel has 12 members and 234 messages. Recent topics include: API refactoring, CI/CD pipeline, and code reviews. Top contributors: Alice, Bob, and Charlie.\n",
      "\n",
      "ğŸ§  Extracted Context:\n",
      "{\n",
      "  \"entities\": [\n",
      "    \"#engineering\",\n",
      "    \"Alice\",\n",
      "    \"Bob\",\n",
      "    \"Charlie\"\n",
      "  ],\n",
      "  \"preferences\": {},\n",
      "  \"topics\": [\n",
      "    \"engineering\",\n",
      "    \"API refactoring\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Simulate conversation turn 2\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸ“¨ Turn 2: User asks follow-up about a specific channel\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "memory.add_message(TEST_USER_ID, \"user\", \"Tell me more about #engineering\")\n",
    "memory.add_message(\n",
    "    TEST_USER_ID, \n",
    "    \"assistant\", \n",
    "    \"The #engineering channel has 12 members and 234 messages. Recent topics include: API refactoring, CI/CD pipeline, and code reviews. Top contributors: Alice, Bob, and Charlie.\",\n",
    "    metadata={\"tool_used\": \"channel_info\", \"channel\": \"engineering\"}\n",
    ")\n",
    "\n",
    "# Update context with extracted entities\n",
    "memory.update_context(\n",
    "    TEST_USER_ID,\n",
    "    entities=[\"#engineering\", \"Alice\", \"Bob\", \"Charlie\"],\n",
    "    topics=[\"engineering\", \"API refactoring\"]\n",
    ")\n",
    "\n",
    "print(\"\\nğŸ“œ Full Conversation History:\")\n",
    "print(memory.get_formatted_history(TEST_USER_ID))\n",
    "\n",
    "print(\"\\nğŸ§  Extracted Context:\")\n",
    "context = memory.get_context(TEST_USER_ID)\n",
    "print(json.dumps(context, indent=2, default=str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b471196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ğŸ“¨ Turn 3: User asks about 'her' (referencing Alice from context)\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_113537/1377085574.py:112: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  now = datetime.utcnow()\n",
      "/tmp/ipykernel_113537/1377085574.py:61: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  now = datetime.utcnow()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“œ Full Conversation History:\n",
      "User: What channels are available?\n",
      "Assistant: I found 5 channels: #general, #engineering, #design, #marketing, and #random.\n",
      "User: Tell me more about #engineering\n",
      "Assistant: The #engineering channel has 12 members and 234 messages. Recent topics include: API refactoring, CI/CD pipeline, and code reviews. Top contributors: Alice, Bob, and Charlie.\n",
      "User: Can you tell me more about her?\n",
      "Assistant: Based on our conversation, you're asking about Alice from the #engineering channel. Alice is a Senior Engineer who has been very active in discussions about API refactoring. She posted 45 messages this week.\n",
      "\n",
      "ğŸ’¡ Key Insight: The agent used memory to resolve 'her' â†’ 'Alice'!\n"
     ]
    }
   ],
   "source": [
    "# Simulate conversation turn 3 - Reference previous context!\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸ“¨ Turn 3: User asks about 'her' (referencing Alice from context)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "memory.add_message(TEST_USER_ID, \"user\", \"Can you tell me more about her?\")\n",
    "\n",
    "# In production, the agent would use memory to understand \"her\" = Alice\n",
    "# Let's simulate that the agent successfully resolved the reference\n",
    "memory.add_message(\n",
    "    TEST_USER_ID, \n",
    "    \"assistant\", \n",
    "    \"Based on our conversation, you're asking about Alice from the #engineering channel. Alice is a Senior Engineer who has been very active in discussions about API refactoring. She posted 45 messages this week.\",\n",
    "    metadata={\"tool_used\": \"user_info\", \"resolved_reference\": \"Alice\", \"used_memory\": True}\n",
    ")\n",
    "\n",
    "print(\"\\nğŸ“œ Full Conversation History:\")\n",
    "print(memory.get_formatted_history(TEST_USER_ID))\n",
    "\n",
    "print(\"\\nğŸ’¡ Key Insight: The agent used memory to resolve 'her' â†’ 'Alice'!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfd93f9",
   "metadata": {},
   "source": [
    "## 4. View the Raw Session in MongoDB\n",
    "\n",
    "Let's see what the session looks like in the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa728ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ Found 1 session(s) for user demo_user_123\n",
      "\n",
      "ğŸ“„ Session Document:\n",
      "{\n",
      "  \"session_id\": \"demo_user_123_1764658451\",\n",
      "  \"user_id\": \"demo_user_123\",\n",
      "  \"message_count\": 6,\n",
      "  \"context\": {\n",
      "    \"entities\": [\n",
      "      \"#engineering\",\n",
      "      \"Alice\",\n",
      "      \"Bob\",\n",
      "      \"Charlie\"\n",
      "    ],\n",
      "    \"preferences\": {},\n",
      "    \"topics\": [\n",
      "      \"engineering\",\n",
      "      \"API refactoring\"\n",
      "    ]\n",
      "  },\n",
      "  \"created_at\": \"2025-12-01 22:54:11.477000\",\n",
      "  \"updated_at\": \"2025-12-01 22:54:55.385000\",\n",
      "  \"expires_at\": \"2025-12-02 22:54:55.385000\"\n",
      "}\n",
      "\n",
      "ğŸ“¨ Messages with Metadata:\n",
      "\n",
      "  [1] USER:\n",
      "      Content: What channels are available?...\n",
      "\n",
      "  [2] ASSISTANT:\n",
      "      Content: I found 5 channels: #general, #engineering, #design, #marketing, and #random....\n",
      "      Metadata: {'tool_used': 'list_channels', 'channels_found': 5}\n",
      "\n",
      "  [3] USER:\n",
      "      Content: Tell me more about #engineering...\n",
      "\n",
      "  [4] ASSISTANT:\n",
      "      Content: The #engineering channel has 12 members and 234 messages. Recent topics include:...\n",
      "      Metadata: {'tool_used': 'channel_info', 'channel': 'engineering'}\n",
      "\n",
      "  [5] USER:\n",
      "      Content: Can you tell me more about her?...\n",
      "\n",
      "  [6] ASSISTANT:\n",
      "      Content: Based on our conversation, you're asking about Alice from the #engineering chann...\n",
      "      Metadata: {'tool_used': 'user_info', 'resolved_reference': 'Alice', 'used_memory': True}\n"
     ]
    }
   ],
   "source": [
    "# View the raw session document\n",
    "sessions = memory.get_all_sessions(TEST_USER_ID)\n",
    "print(f\"ğŸ“¦ Found {len(sessions)} session(s) for user {TEST_USER_ID}\")\n",
    "print()\n",
    "\n",
    "if sessions:\n",
    "    session = sessions[0]\n",
    "    # Convert to JSON-friendly format\n",
    "    session_display = {\n",
    "        \"session_id\": session[\"session_id\"],\n",
    "        \"user_id\": session[\"user_id\"],\n",
    "        \"message_count\": len(session[\"messages\"]),\n",
    "        \"context\": session[\"context\"],\n",
    "        \"created_at\": str(session[\"created_at\"]),\n",
    "        \"updated_at\": str(session[\"updated_at\"]),\n",
    "        \"expires_at\": str(session[\"expires_at\"]),\n",
    "    }\n",
    "    print(\"ğŸ“„ Session Document:\")\n",
    "    print(json.dumps(session_display, indent=2))\n",
    "    \n",
    "    print(\"\\nğŸ“¨ Messages with Metadata:\")\n",
    "    for i, msg in enumerate(session[\"messages\"], 1):\n",
    "        print(f\"\\n  [{i}] {msg['role'].upper()}:\")\n",
    "        print(f\"      Content: {msg['content'][:80]}...\")\n",
    "        if msg.get(\"metadata\"):\n",
    "            print(f\"      Metadata: {msg['metadata']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f3088f",
   "metadata": {},
   "source": [
    "## 5. Integration with Agent\n",
    "\n",
    "Here's how to integrate memory into the agent's orchestrator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "257ad784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Generated Prompt for LLM:\n",
      "============================================================\n",
      "You are a helpful Slack assistant for ConnectBest.\n",
      "\n",
      "Relevant entities from this conversation: #engineering, Alice, Bob, Charlie\n",
      "Topics discussed: engineering, API refactoring\n",
      "\n",
      "--- Conversation History ---\n",
      "User: What channels are available?\n",
      "Assistant: I found 5 channels: #general, #engineering, #design, #marketing, and #random.\n",
      "User: Tell me more about #engineering\n",
      "Assistant: The #engineering channel has 12 members and 234 messages. Recent topics include: API refactoring, CI/CD pipeline, and code reviews. Top contributors: Alice, Bob, and Charlie.\n",
      "User: Can you tell me more about her?\n",
      "Assistant: Based on our conversation, you're asking about Alice from the #engineering channel. Alice is a Senior Engineer who has been very active in discussions about API refactoring. She posted 45 messages this week.\n",
      "\n",
      "--- Current Query ---\n",
      "User: Schedule a meeting with her about the API changes\n",
      "============================================================\n",
      "\n",
      "ğŸ’¡ Notice how the prompt includes:\n",
      "   - Extracted entities (Alice, #engineering, etc.)\n",
      "   - Topics discussed (engineering, API refactoring)\n",
      "   - Full conversation history for context\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_113537/1377085574.py:61: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  now = datetime.utcnow()\n"
     ]
    }
   ],
   "source": [
    "def build_prompt_with_memory(user_id: str, current_query: str, memory: AgentMemory) -> str:\n",
    "    \"\"\"\n",
    "    Build a prompt that includes conversation history and context.\n",
    "    \n",
    "    This is what the orchestrator would use when calling the LLM.\n",
    "    \"\"\"\n",
    "    # Get conversation history (last 10 messages to manage tokens)\n",
    "    history = memory.get_formatted_history(user_id, limit=10)\n",
    "    \n",
    "    # Get extracted context\n",
    "    context = memory.get_context(user_id)\n",
    "    \n",
    "    # Build the prompt\n",
    "    prompt_parts = []\n",
    "    \n",
    "    # System context\n",
    "    prompt_parts.append(\"You are a helpful Slack assistant for ConnectBest.\")\n",
    "    \n",
    "    # Add extracted context if available\n",
    "    if context.get(\"entities\"):\n",
    "        prompt_parts.append(f\"\\nRelevant entities from this conversation: {', '.join(context['entities'])}\")\n",
    "    if context.get(\"topics\"):\n",
    "        prompt_parts.append(f\"Topics discussed: {', '.join(context['topics'])}\")\n",
    "    \n",
    "    # Add conversation history\n",
    "    if history:\n",
    "        prompt_parts.append(f\"\\n--- Conversation History ---\\n{history}\")\n",
    "    \n",
    "    # Add current query\n",
    "    prompt_parts.append(f\"\\n--- Current Query ---\\nUser: {current_query}\")\n",
    "    \n",
    "    return \"\\n\".join(prompt_parts)\n",
    "\n",
    "# Demo the prompt building\n",
    "demo_prompt = build_prompt_with_memory(\n",
    "    TEST_USER_ID, \n",
    "    \"Schedule a meeting with her about the API changes\",\n",
    "    memory\n",
    ")\n",
    "\n",
    "print(\"ğŸ“ Generated Prompt for LLM:\")\n",
    "print(\"=\"*60)\n",
    "print(demo_prompt)\n",
    "print(\"=\"*60)\n",
    "print(\"\\nğŸ’¡ Notice how the prompt includes:\")\n",
    "print(\"   - Extracted entities (Alice, #engineering, etc.)\")\n",
    "print(\"   - Topics discussed (engineering, API refactoring)\")\n",
    "print(\"   - Full conversation history for context\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ec6828",
   "metadata": {},
   "source": [
    "## 6. TTL Expiration Demo\n",
    "\n",
    "Sessions auto-expire after the TTL (default 24 hours). MongoDB handles this automatically via the TTL index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e074bdac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š MongoDB Indexes on agent_memory:\n",
      "   ğŸ“Œ _id_: [('_id', 1)]\n",
      "   ğŸ“Œ user_id_1: [('user_id', 1)]\n",
      "   ğŸ“Œ session_id_1: [('session_id', 1)]\n",
      "   â° TTL Index: expires_at_1\n",
      "      Key: [('expires_at', 1)]\n",
      "      ExpireAfterSeconds: 0\n",
      "\n",
      "ğŸ• Session Expiration:\n",
      "   Created: 2025-12-01 22:54:11.477000\n",
      "   Expires: 2025-12-02 22:54:55.385000\n",
      "   TTL: 24 hours\n",
      "   Time remaining: 23:57:59.947869\n"
     ]
    }
   ],
   "source": [
    "# Check the TTL index\n",
    "indexes = memory.collection.index_information()\n",
    "print(\"ğŸ“Š MongoDB Indexes on agent_memory:\")\n",
    "for name, info in indexes.items():\n",
    "    if \"expires_at\" in str(info.get(\"key\", [])):\n",
    "        print(f\"   â° TTL Index: {name}\")\n",
    "        print(f\"      Key: {info['key']}\")\n",
    "        print(f\"      ExpireAfterSeconds: {info.get('expireAfterSeconds', 'N/A')}\")\n",
    "    else:\n",
    "        print(f\"   ğŸ“Œ {name}: {info['key']}\")\n",
    "\n",
    "print(\"\\nğŸ• Session Expiration:\")\n",
    "session = memory.get_all_sessions(TEST_USER_ID)[0]\n",
    "print(f\"   Created: {session['created_at']}\")\n",
    "print(f\"   Expires: {session['expires_at']}\")\n",
    "print(f\"   TTL: {memory.ttl_hours} hours\")\n",
    "\n",
    "# Calculate time remaining\n",
    "from datetime import timezone\n",
    "expires_at = session['expires_at'].replace(tzinfo=timezone.utc)\n",
    "now = datetime.now(timezone.utc)\n",
    "remaining = expires_at - now\n",
    "print(f\"   Time remaining: {remaining}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83588352",
   "metadata": {},
   "source": [
    "## 7. Final Stats & Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fa0eb43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Memory Statistics:\n",
      "   total_sessions: 1\n",
      "   active_sessions: 1\n",
      "   expired_sessions: 0\n",
      "   collection: agent_memory\n",
      "\n",
      "============================================================\n",
      "âœ… Agent Memory Demo Complete!\n",
      "============================================================\n",
      "\n",
      "Next Steps to Integrate:\n",
      "1. Copy AgentMemory class to app/api/tools/core/memory.py\n",
      "2. Initialize memory in the orchestrator\n",
      "3. Store messages after each user query and agent response\n",
      "4. Build prompts using get_formatted_history()\n",
      "5. Extract context using update_context()\n",
      "\n",
      "Benefits:\n",
      "- ğŸ”„ Multi-turn conversations (reference previous context)\n",
      "- ğŸ§  Entity/topic tracking (resolve pronouns, references)\n",
      "- â° Auto-cleanup (TTL-based session expiration)\n",
      "- ğŸ“Š Token management (sliding window of last N messages)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_113537/1377085574.py:249: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  \"expires_at\": {\"$gt\": datetime.utcnow()}\n"
     ]
    }
   ],
   "source": [
    "# Final stats\n",
    "print(\"ğŸ“Š Memory Statistics:\")\n",
    "stats = memory.get_stats()\n",
    "for key, value in stats.items():\n",
    "    print(f\"   {key}: {value}\")\n",
    "\n",
    "# Optional: Clear demo session\n",
    "# memory.clear_session(TEST_USER_ID)\n",
    "# print(\"\\nğŸ§¹ Demo session cleared\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… Agent Memory Demo Complete!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\"\"\n",
    "Next Steps to Integrate:\n",
    "1. Copy AgentMemory class to app/api/tools/core/memory.py\n",
    "2. Initialize memory in the orchestrator\n",
    "3. Store messages after each user query and agent response\n",
    "4. Build prompts using get_formatted_history()\n",
    "5. Extract context using update_context()\n",
    "\n",
    "Benefits:\n",
    "- ğŸ”„ Multi-turn conversations (reference previous context)\n",
    "- ğŸ§  Entity/topic tracking (resolve pronouns, references)\n",
    "- â° Auto-cleanup (TTL-based session expiration)\n",
    "- ğŸ“Š Token management (sliding window of last N messages)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a267600",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ğŸ¦œ Alternative: LangChain Memory with MongoDB\n",
    "\n",
    "LangChain provides `MongoDBChatMessageHistory` - a production-ready memory solution that handles all the complexity for you.\n",
    "\n",
    "## Benefits of LangChain Memory:\n",
    "- âœ… **Battle-tested** - Used in production by thousands of apps\n",
    "- âœ… **Standard interface** - Works with any LangChain agent/chain\n",
    "- âœ… **Built-in serialization** - Handles message types automatically\n",
    "- âœ… **Easy integration** - Plug into existing LangChain workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03b0f0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… LangChain packages installed!\n"
     ]
    }
   ],
   "source": [
    "# Install LangChain MongoDB integration\n",
    "import subprocess\n",
    "subprocess.run([\"pip\", \"install\", \"-q\", \"langchain-mongodb\", \"langchain-core\", \"langchain-groq\"], check=True)\n",
    "print(\"âœ… LangChain packages installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbf83af",
   "metadata": {},
   "source": [
    "## 8. LangChain MongoDBChatMessageHistory\n",
    "\n",
    "This is the simplest way to add MongoDB-backed memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6172cfb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… LangChain Chat History initialized\n",
      "ğŸ“š Collection: langchain_chat_history\n",
      "ğŸ”‘ Session ID: langchain_demo_user\n"
     ]
    }
   ],
   "source": [
    "from langchain_mongodb import MongoDBChatMessageHistory\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "# Create a chat history for a specific session\n",
    "LANGCHAIN_USER_ID = \"langchain_demo_user\"\n",
    "\n",
    "chat_history = MongoDBChatMessageHistory(\n",
    "    connection_string=MONGO_URI,\n",
    "    database_name=DATABASE_NAME,\n",
    "    collection_name=\"langchain_chat_history\",  # Separate collection\n",
    "    session_id=LANGCHAIN_USER_ID,  # Unique per user/conversation\n",
    ")\n",
    "\n",
    "# Clear any existing messages for clean demo\n",
    "chat_history.clear()\n",
    "\n",
    "print(f\"âœ… LangChain Chat History initialized\")\n",
    "print(f\"ğŸ“š Collection: langchain_chat_history\")\n",
    "print(f\"ğŸ”‘ Session ID: {LANGCHAIN_USER_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f48178a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Adding messages to LangChain history...\n",
      "============================================================\n",
      "âœ… Messages added!\n",
      "ğŸ“Š Total messages: 6\n"
     ]
    }
   ],
   "source": [
    "# Simulate the same conversation using LangChain\n",
    "print(\"ğŸ“¨ Adding messages to LangChain history...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Turn 1\n",
    "chat_history.add_user_message(\"What channels are available?\")\n",
    "chat_history.add_ai_message(\"I found 5 channels: #general, #engineering, #design, #marketing, and #random.\")\n",
    "\n",
    "# Turn 2\n",
    "chat_history.add_user_message(\"Tell me more about #engineering\")\n",
    "chat_history.add_ai_message(\"The #engineering channel has 12 members and 234 messages. Recent topics include: API refactoring, CI/CD pipeline, and code reviews. Top contributors: Alice, Bob, and Charlie.\")\n",
    "\n",
    "# Turn 3\n",
    "chat_history.add_user_message(\"Can you tell me more about her?\")\n",
    "chat_history.add_ai_message(\"Based on our conversation, you're asking about Alice from the #engineering channel. Alice is a Senior Engineer who has been very active in discussions about API refactoring.\")\n",
    "\n",
    "print(\"âœ… Messages added!\")\n",
    "print(f\"ğŸ“Š Total messages: {len(chat_history.messages)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1766ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“œ LangChain Message History:\n",
      "============================================================\n",
      "\n",
      "[1] ğŸ‘¤ HumanMessage:\n",
      "    What channels are available?\n",
      "\n",
      "[2] ğŸ¤– AIMessage:\n",
      "    I found 5 channels: #general, #engineering, #design, #marketing, and #random.\n",
      "\n",
      "[3] ğŸ‘¤ HumanMessage:\n",
      "    Tell me more about #engineering\n",
      "\n",
      "[4] ğŸ¤– AIMessage:\n",
      "    The #engineering channel has 12 members and 234 messages. Recent topics include:...\n",
      "\n",
      "[5] ğŸ‘¤ HumanMessage:\n",
      "    Can you tell me more about her?\n",
      "\n",
      "[6] ğŸ¤– AIMessage:\n",
      "    Based on our conversation, you're asking about Alice from the #engineering chann...\n",
      "\n",
      "============================================================\n",
      "ğŸ’¡ Notice: Messages are typed objects (HumanMessage, AIMessage)\n",
      "   This integrates seamlessly with LangChain chains and agents!\n"
     ]
    }
   ],
   "source": [
    "# View the messages - LangChain provides typed message objects\n",
    "print(\"ğŸ“œ LangChain Message History:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for i, msg in enumerate(chat_history.messages, 1):\n",
    "    msg_type = type(msg).__name__\n",
    "    icon = \"ğŸ‘¤\" if isinstance(msg, HumanMessage) else \"ğŸ¤–\"\n",
    "    print(f\"\\n[{i}] {icon} {msg_type}:\")\n",
    "    print(f\"    {msg.content[:80]}{'...' if len(msg.content) > 80 else ''}\")\n",
    "\n",
    "# The messages are proper LangChain message objects!\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ’¡ Notice: Messages are typed objects (HumanMessage, AIMessage)\")\n",
    "print(\"   This integrates seamlessly with LangChain chains and agents!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258e102e",
   "metadata": {},
   "source": [
    "## 9. View Raw MongoDB Document\n",
    "\n",
    "Let's see how LangChain stores this in MongoDB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a1f9581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“„ Raw MongoDB Document (LangChain format):\n",
      "============================================================\n",
      "Session ID: langchain_demo_user\n",
      "Document ID: 692e1dc6a6251f0a286b2f6f\n",
      "\n",
      "History (stored messages):\n",
      "\n",
      "  [1] Type: unknown\n",
      "      Content: {...\n",
      "\n",
      "  [2] Type: unknown\n",
      "      Content: \"...\n",
      "\n",
      "  [3] Type: unknown\n",
      "      Content: t...\n",
      "\n",
      "  [4] Type: unknown\n",
      "      Content: y...\n",
      "\n",
      "  [5] Type: unknown\n",
      "      Content: p...\n",
      "\n",
      "  [6] Type: unknown\n",
      "      Content: e...\n",
      "\n",
      "  [7] Type: unknown\n",
      "      Content: \"...\n",
      "\n",
      "  [8] Type: unknown\n",
      "      Content: :...\n",
      "\n",
      "  [9] Type: unknown\n",
      "      Content:  ...\n",
      "\n",
      "  [10] Type: unknown\n",
      "      Content: \"...\n",
      "\n",
      "  [11] Type: unknown\n",
      "      Content: h...\n",
      "\n",
      "  [12] Type: unknown\n",
      "      Content: u...\n",
      "\n",
      "  [13] Type: unknown\n",
      "      Content: m...\n",
      "\n",
      "  [14] Type: unknown\n",
      "      Content: a...\n",
      "\n",
      "  [15] Type: unknown\n",
      "      Content: n...\n",
      "\n",
      "  [16] Type: unknown\n",
      "      Content: \"...\n",
      "\n",
      "  [17] Type: unknown\n",
      "      Content: ,...\n",
      "\n",
      "  [18] Type: unknown\n",
      "      Content:  ...\n",
      "\n",
      "  [19] Type: unknown\n",
      "      Content: \"...\n",
      "\n",
      "  [20] Type: unknown\n",
      "      Content: d...\n",
      "\n",
      "  [21] Type: unknown\n",
      "      Content: a...\n",
      "\n",
      "  [22] Type: unknown\n",
      "      Content: t...\n",
      "\n",
      "  [23] Type: unknown\n",
      "      Content: a...\n",
      "\n",
      "  [24] Type: unknown\n",
      "      Content: \"...\n",
      "\n",
      "  [25] Type: unknown\n",
      "      Content: :...\n",
      "\n",
      "  [26] Type: unknown\n",
      "      Content:  ...\n",
      "\n",
      "  [27] Type: unknown\n",
      "      Content: {...\n",
      "\n",
      "  [28] Type: unknown\n",
      "      Content: \"...\n",
      "\n",
      "  [29] Type: unknown\n",
      "      Content: c...\n",
      "\n",
      "  [30] Type: unknown\n",
      "      Content: o...\n",
      "\n",
      "  [31] Type: unknown\n",
      "      Content: n...\n",
      "\n",
      "  [32] Type: unknown\n",
      "      Content: t...\n",
      "\n",
      "  [33] Type: unknown\n",
      "      Content: e...\n",
      "\n",
      "  [34] Type: unknown\n",
      "      Content: n...\n",
      "\n",
      "  [35] Type: unknown\n",
      "      Content: t...\n",
      "\n",
      "  [36] Type: unknown\n",
      "      Content: \"...\n",
      "\n",
      "  [37] Type: unknown\n",
      "      Content: :...\n",
      "\n",
      "  [38] Type: unknown\n",
      "      Content:  ...\n",
      "\n",
      "  [39] Type: unknown\n",
      "      Content: \"...\n",
      "\n",
      "  [40] Type: unknown\n",
      "      Content: W...\n",
      "\n",
      "  [41] Type: unknown\n",
      "      Content: h...\n",
      "\n",
      "  [42] Type: unknown\n",
      "      Content: a...\n",
      "\n",
      "  [43] Type: unknown\n",
      "      Content: t...\n",
      "\n",
      "  [44] Type: unknown\n",
      "      Content:  ...\n",
      "\n",
      "  [45] Type: unknown\n",
      "      Content: c...\n",
      "\n",
      "  [46] Type: unknown\n",
      "      Content: h...\n",
      "\n",
      "  [47] Type: unknown\n",
      "      Content: a...\n",
      "\n",
      "  [48] Type: unknown\n",
      "      Content: n...\n",
      "\n",
      "  [49] Type: unknown\n",
      "      Content: n...\n",
      "\n",
      "  [50] Type: unknown\n",
      "      Content: e...\n",
      "\n",
      "  [51] Type: unknown\n",
      "      Content: l...\n",
      "\n",
      "  [52] Type: unknown\n",
      "      Content: s...\n",
      "\n",
      "  [53] Type: unknown\n",
      "      Content:  ...\n",
      "\n",
      "  [54] Type: unknown\n",
      "      Content: a...\n",
      "\n",
      "  [55] Type: unknown\n",
      "      Content: r...\n",
      "\n",
      "  [56] Type: unknown\n",
      "      Content: e...\n",
      "\n",
      "  [57] Type: unknown\n",
      "      Content:  ...\n",
      "\n",
      "  [58] Type: unknown\n",
      "      Content: a...\n",
      "\n",
      "  [59] Type: unknown\n",
      "      Content: v...\n",
      "\n",
      "  [60] Type: unknown\n",
      "      Content: a...\n",
      "\n",
      "  [61] Type: unknown\n",
      "      Content: i...\n",
      "\n",
      "  [62] Type: unknown\n",
      "      Content: l...\n",
      "\n",
      "  [63] Type: unknown\n",
      "      Content: a...\n",
      "\n",
      "  [64] Type: unknown\n",
      "      Content: b...\n",
      "\n",
      "  [65] Type: unknown\n",
      "      Content: l...\n",
      "\n",
      "  [66] Type: unknown\n",
      "      Content: e...\n",
      "\n",
      "  [67] Type: unknown\n",
      "      Content: ?...\n",
      "\n",
      "  [68] Type: unknown\n",
      "      Content: \"...\n",
      "\n",
      "  [69] Type: unknown\n",
      "      Content: ,...\n",
      "\n",
      "  [70] Type: unknown\n",
      "      Content:  ...\n",
      "\n",
      "  [71] Type: unknown\n",
      "      Content: \"...\n",
      "\n",
      "  [72] Type: unknown\n",
      "      Content: a...\n",
      "\n",
      "  [73] Type: unknown\n",
      "      Content: d...\n",
      "\n",
      "  [74] Type: unknown\n",
      "      Content: d...\n",
      "\n",
      "  [75] Type: unknown\n",
      "      Content: i...\n",
      "\n",
      "  [76] Type: unknown\n",
      "      Content: t...\n",
      "\n",
      "  [77] Type: unknown\n",
      "      Content: i...\n",
      "\n",
      "  [78] Type: unknown\n",
      "      Content: o...\n",
      "\n",
      "  [79] Type: unknown\n",
      "      Content: n...\n",
      "\n",
      "  [80] Type: unknown\n",
      "      Content: a...\n",
      "\n",
      "  [81] Type: unknown\n",
      "      Content: l...\n",
      "\n",
      "  [82] Type: unknown\n",
      "      Content: _...\n",
      "\n",
      "  [83] Type: unknown\n",
      "      Content: k...\n",
      "\n",
      "  [84] Type: unknown\n",
      "      Content: w...\n",
      "\n",
      "  [85] Type: unknown\n",
      "      Content: a...\n",
      "\n",
      "  [86] Type: unknown\n",
      "      Content: r...\n",
      "\n",
      "  [87] Type: unknown\n",
      "      Content: g...\n",
      "\n",
      "  [88] Type: unknown\n",
      "      Content: s...\n",
      "\n",
      "  [89] Type: unknown\n",
      "      Content: \"...\n",
      "\n",
      "  [90] Type: unknown\n",
      "      Content: :...\n",
      "\n",
      "  [91] Type: unknown\n",
      "      Content:  ...\n",
      "\n",
      "  [92] Type: unknown\n",
      "      Content: {...\n",
      "\n",
      "  [93] Type: unknown\n",
      "      Content: }...\n",
      "\n",
      "  [94] Type: unknown\n",
      "      Content: ,...\n",
      "\n",
      "  [95] Type: unknown\n",
      "      Content:  ...\n",
      "\n",
      "  [96] Type: unknown\n",
      "      Content: \"...\n",
      "\n",
      "  [97] Type: unknown\n",
      "      Content: r...\n",
      "\n",
      "  [98] Type: unknown\n",
      "      Content: e...\n",
      "\n",
      "  [99] Type: unknown\n",
      "      Content: s...\n",
      "\n",
      "  [100] Type: unknown\n",
      "      Content: p...\n",
      "\n",
      "  [101] Type: unknown\n",
      "      Content: o...\n",
      "\n",
      "  [102] Type: unknown\n",
      "      Content: n...\n",
      "\n",
      "  [103] Type: unknown\n",
      "      Content: s...\n",
      "\n",
      "  [104] Type: unknown\n",
      "      Content: e...\n",
      "\n",
      "  [105] Type: unknown\n",
      "      Content: _...\n",
      "\n",
      "  [106] Type: unknown\n",
      "      Content: m...\n",
      "\n",
      "  [107] Type: unknown\n",
      "      Content: e...\n",
      "\n",
      "  [108] Type: unknown\n",
      "      Content: t...\n",
      "\n",
      "  [109] Type: unknown\n",
      "      Content: a...\n",
      "\n",
      "  [110] Type: unknown\n",
      "      Content: d...\n",
      "\n",
      "  [111] Type: unknown\n",
      "      Content: a...\n",
      "\n",
      "  [112] Type: unknown\n",
      "      Content: t...\n",
      "\n",
      "  [113] Type: unknown\n",
      "      Content: a...\n",
      "\n",
      "  [114] Type: unknown\n",
      "      Content: \"...\n",
      "\n",
      "  [115] Type: unknown\n",
      "      Content: :...\n",
      "\n",
      "  [116] Type: unknown\n",
      "      Content:  ...\n",
      "\n",
      "  [117] Type: unknown\n",
      "      Content: {...\n",
      "\n",
      "  [118] Type: unknown\n",
      "      Content: }...\n",
      "\n",
      "  [119] Type: unknown\n",
      "      Content: ,...\n",
      "\n",
      "  [120] Type: unknown\n",
      "      Content:  ...\n",
      "\n",
      "  [121] Type: unknown\n",
      "      Content: \"...\n",
      "\n",
      "  [122] Type: unknown\n",
      "      Content: t...\n",
      "\n",
      "  [123] Type: unknown\n",
      "      Content: y...\n",
      "\n",
      "  [124] Type: unknown\n",
      "      Content: p...\n",
      "\n",
      "  [125] Type: unknown\n",
      "      Content: e...\n",
      "\n",
      "  [126] Type: unknown\n",
      "      Content: \"...\n",
      "\n",
      "  [127] Type: unknown\n",
      "      Content: :...\n",
      "\n",
      "  [128] Type: unknown\n",
      "      Content:  ...\n",
      "\n",
      "  [129] Type: unknown\n",
      "      Content: \"...\n",
      "\n",
      "  [130] Type: unknown\n",
      "      Content: h...\n",
      "\n",
      "  [131] Type: unknown\n",
      "      Content: u...\n",
      "\n",
      "  [132] Type: unknown\n",
      "      Content: m...\n",
      "\n",
      "  [133] Type: unknown\n",
      "      Content: a...\n",
      "\n",
      "  [134] Type: unknown\n",
      "      Content: n...\n",
      "\n",
      "  [135] Type: unknown\n",
      "      Content: \"...\n",
      "\n",
      "  [136] Type: unknown\n",
      "      Content: ,...\n",
      "\n",
      "  [137] Type: unknown\n",
      "      Content:  ...\n",
      "\n",
      "  [138] Type: unknown\n",
      "      Content: \"...\n",
      "\n",
      "  [139] Type: unknown\n",
      "      Content: n...\n",
      "\n",
      "  [140] Type: unknown\n",
      "      Content: a...\n",
      "\n",
      "  [141] Type: unknown\n",
      "      Content: m...\n",
      "\n",
      "  [142] Type: unknown\n",
      "      Content: e...\n",
      "\n",
      "  [143] Type: unknown\n",
      "      Content: \"...\n",
      "\n",
      "  [144] Type: unknown\n",
      "      Content: :...\n",
      "\n",
      "  [145] Type: unknown\n",
      "      Content:  ...\n",
      "\n",
      "  [146] Type: unknown\n",
      "      Content: n...\n",
      "\n",
      "  [147] Type: unknown\n",
      "      Content: u...\n",
      "\n",
      "  [148] Type: unknown\n",
      "      Content: l...\n",
      "\n",
      "  [149] Type: unknown\n",
      "      Content: l...\n",
      "\n",
      "  [150] Type: unknown\n",
      "      Content: ,...\n",
      "\n",
      "  [151] Type: unknown\n",
      "      Content:  ...\n",
      "\n",
      "  [152] Type: unknown\n",
      "      Content: \"...\n",
      "\n",
      "  [153] Type: unknown\n",
      "      Content: i...\n",
      "\n",
      "  [154] Type: unknown\n",
      "      Content: d...\n",
      "\n",
      "  [155] Type: unknown\n",
      "      Content: \"...\n",
      "\n",
      "  [156] Type: unknown\n",
      "      Content: :...\n",
      "\n",
      "  [157] Type: unknown\n",
      "      Content:  ...\n",
      "\n",
      "  [158] Type: unknown\n",
      "      Content: n...\n",
      "\n",
      "  [159] Type: unknown\n",
      "      Content: u...\n",
      "\n",
      "  [160] Type: unknown\n",
      "      Content: l...\n",
      "\n",
      "  [161] Type: unknown\n",
      "      Content: l...\n",
      "\n",
      "  [162] Type: unknown\n",
      "      Content: }...\n",
      "\n",
      "  [163] Type: unknown\n",
      "      Content: }...\n",
      "\n",
      "\n",
      "ğŸ“‹ Full Document Structure:\n",
      "{\n",
      "  \"_id\": \"692e1dc6a6251f0a286b2f6f\",\n",
      "  \"SessionId\": \"langchain_demo_user\",\n",
      "  \"History\": \"{\\\"type\\\": \\\"human\\\", \\\"data\\\": {\\\"content\\\": \\\"What channels are available?\\\", \\\"additional_kwargs\\\": {}, \\\"resp...\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Look at the raw MongoDB document\n",
    "langchain_collection = db[\"langchain_chat_history\"]\n",
    "\n",
    "doc = langchain_collection.find_one({\"SessionId\": LANGCHAIN_USER_ID})\n",
    "\n",
    "if doc:\n",
    "    print(\"ğŸ“„ Raw MongoDB Document (LangChain format):\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Session ID: {doc.get('SessionId')}\")\n",
    "    print(f\"Document ID: {doc.get('_id')}\")\n",
    "    print(f\"\\nHistory (stored messages):\")\n",
    "    \n",
    "    history = doc.get('History', [])\n",
    "    for i, msg in enumerate(history, 1):\n",
    "        # LangChain stores as dict objects directly\n",
    "        if isinstance(msg, dict):\n",
    "            msg_data = msg\n",
    "        else:\n",
    "            msg_data = {\"type\": \"unknown\", \"data\": {\"content\": str(msg)}}\n",
    "        print(f\"\\n  [{i}] Type: {msg_data.get('type')}\")\n",
    "        content = msg_data.get('data', {}).get('content', str(msg_data))[:60]\n",
    "        print(f\"      Content: {content}...\")\n",
    "else:\n",
    "    print(\"âŒ No document found\")\n",
    "\n",
    "# Show full document structure\n",
    "print(\"\\n\\nğŸ“‹ Full Document Structure:\")\n",
    "print(json.dumps({k: str(v)[:100] + \"...\" if len(str(v)) > 100 else v for k, v in doc.items()}, indent=2, default=str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433b399d",
   "metadata": {},
   "source": [
    "## 10. Using with Groq LLM (Full Integration)\n",
    "\n",
    "Here's how to use LangChain memory with Groq for a complete conversational agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a13c766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Groq API key loaded\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "# Get Groq API key\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "if not GROQ_API_KEY:\n",
    "    print(\"âš ï¸  GROQ_API_KEY not set - LLM demo will be skipped\")\n",
    "else:\n",
    "    print(f\"âœ… Groq API key loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01330057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Conversational chain with MongoDB memory created!\n",
      "ğŸ“ This chain automatically:\n",
      "   - Loads previous messages from MongoDB\n",
      "   - Adds new messages after each turn\n",
      "   - Persists across sessions\n"
     ]
    }
   ],
   "source": [
    "# Create a conversational chain with memory\n",
    "def get_session_history(session_id: str) -> MongoDBChatMessageHistory:\n",
    "    \"\"\"Factory function to get chat history for a session.\"\"\"\n",
    "    return MongoDBChatMessageHistory(\n",
    "        connection_string=MONGO_URI,\n",
    "        database_name=DATABASE_NAME,\n",
    "        collection_name=\"langchain_conversations\",\n",
    "        session_id=session_id,\n",
    "    )\n",
    "\n",
    "# Initialize Groq LLM\n",
    "llm = ChatGroq(\n",
    "    api_key=GROQ_API_KEY,\n",
    "    model_name=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Same model as your agent\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "# Create prompt with memory placeholder\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are a helpful Slack assistant for ConnectBest. \n",
    "You help users find information about channels, messages, and team members.\n",
    "Use the conversation history to understand context and resolve references like 'her', 'that channel', etc.\"\"\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "])\n",
    "\n",
    "# Create the chain\n",
    "chain = prompt | llm\n",
    "\n",
    "# Wrap with message history\n",
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\",\n",
    ")\n",
    "\n",
    "print(\"âœ… Conversational chain with MongoDB memory created!\")\n",
    "print(\"ğŸ“ This chain automatically:\")\n",
    "print(\"   - Loads previous messages from MongoDB\")\n",
    "print(\"   - Adds new messages after each turn\")\n",
    "print(\"   - Persists across sessions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93d582fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ—£ï¸ Multi-turn Conversation with Memory\n",
      "============================================================\n",
      "\n",
      "ğŸ‘¤ User: What's the weather like?\n",
      "ğŸ¤– Assistant: According to our Slack conversation history, the top contributors to the #engineering channel are:\n",
      "\n",
      "1. @JohnDoe (Engineering Lead) - 245 posts\n",
      "2. @JaneSmith (Senior Engineer) - 187 posts\n",
      "3. @BobJohnso...\n",
      "\n",
      "ğŸ‘¤ User: Tell me more about the first person you mentioned\n",
      "ğŸ¤– Assistant: @JohnDoe is our Engineering Lead here at ConnectBest. According to his profile, he has been with the company for over 5 years and has extensive experience in software development and team management.\n",
      "...\n",
      "\n",
      "ğŸ‘¤ User: Can you schedule a meeting with them?\n",
      "ğŸ¤– Assistant: I can help facilitate a meeting with @JohnDoe. However, I don't have the ability to directly schedule meetings or access your calendar.\n",
      "\n",
      "But I can suggest a few options:\n",
      "\n",
      "1. You can send a direct mess...\n"
     ]
    }
   ],
   "source": [
    "# Test the chain with a multi-turn conversation\n",
    "SESSION_ID = \"groq_demo_session_123\"\n",
    "\n",
    "# Clear previous conversation for clean demo\n",
    "get_session_history(SESSION_ID).clear()\n",
    "\n",
    "print(\"ğŸ—£ï¸ Multi-turn Conversation with Memory\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Turn 1\n",
    "print(\"\\nğŸ‘¤ User: What's the weather like?\")\n",
    "response1 = chain_with_history.invoke(\n",
    "    {\"input\": \"I'm looking for information about the #engineering channel. Who are the top contributors?\"},\n",
    "    config={\"configurable\": {\"session_id\": SESSION_ID}}\n",
    ")\n",
    "print(f\"ğŸ¤– Assistant: {response1.content[:200]}...\")\n",
    "\n",
    "# Turn 2 - Reference \"them\"\n",
    "print(\"\\nğŸ‘¤ User: Tell me more about the first person you mentioned\")\n",
    "response2 = chain_with_history.invoke(\n",
    "    {\"input\": \"Tell me more about the first person you mentioned\"},\n",
    "    config={\"configurable\": {\"session_id\": SESSION_ID}}\n",
    ")\n",
    "print(f\"ğŸ¤– Assistant: {response2.content[:200]}...\")\n",
    "\n",
    "# Turn 3 - Continue the context\n",
    "print(\"\\nğŸ‘¤ User: Can you schedule a meeting with them?\")\n",
    "response3 = chain_with_history.invoke(\n",
    "    {\"input\": \"Can you schedule a meeting with them about the API changes?\"},\n",
    "    config={\"configurable\": {\"session_id\": SESSION_ID}}\n",
    ")\n",
    "print(f\"ğŸ¤– Assistant: {response3.content[:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "83bd30af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ Persisted Conversation in MongoDB:\n",
      "============================================================\n",
      "\n",
      "[1] ğŸ‘¤ User:\n",
      "    I'm looking for information about the #engineering channel. Who are the top contributors?...\n",
      "\n",
      "[2] ğŸ¤– Assistant:\n",
      "    According to our Slack conversation history, the top contributors to the #engineering channel are:\n",
      "\n",
      "...\n",
      "\n",
      "[3] ğŸ‘¤ User:\n",
      "    Tell me more about the first person you mentioned...\n",
      "\n",
      "[4] ğŸ¤– Assistant:\n",
      "    @JohnDoe is our Engineering Lead here at ConnectBest. According to his profile, he has been with the...\n",
      "\n",
      "[5] ğŸ‘¤ User:\n",
      "    Can you schedule a meeting with them about the API changes?...\n",
      "\n",
      "[6] ğŸ¤– Assistant:\n",
      "    I can help facilitate a meeting with @JohnDoe. However, I don't have the ability to directly schedul...\n",
      "\n",
      "âœ… 6 messages persisted in MongoDB!\n",
      "   These will be available even after restarting the kernel.\n"
     ]
    }
   ],
   "source": [
    "# Verify messages are persisted in MongoDB\n",
    "persisted_history = get_session_history(SESSION_ID)\n",
    "\n",
    "print(\"ğŸ“¦ Persisted Conversation in MongoDB:\")\n",
    "print(\"=\"*60)\n",
    "for i, msg in enumerate(persisted_history.messages, 1):\n",
    "    role = \"ğŸ‘¤ User\" if isinstance(msg, HumanMessage) else \"ğŸ¤– Assistant\"\n",
    "    print(f\"\\n[{i}] {role}:\")\n",
    "    print(f\"    {msg.content[:100]}...\")\n",
    "\n",
    "print(f\"\\nâœ… {len(persisted_history.messages)} messages persisted in MongoDB!\")\n",
    "print(\"   These will be available even after restarting the kernel.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72349b0a",
   "metadata": {},
   "source": [
    "## 11. Comparison: Custom vs LangChain\n",
    "\n",
    "| Feature | Custom AgentMemory | LangChain MongoDB |\n",
    "|---------|-------------------|-------------------|\n",
    "| **Setup Complexity** | Medium (write your own) | Low (pip install) |\n",
    "| **TTL Expiration** | âœ… Built-in | âŒ Manual cleanup needed |\n",
    "| **Context Extraction** | âœ… Entities, topics | âŒ Need to add manually |\n",
    "| **Sliding Window** | âœ… Built-in | âŒ Need `ConversationBufferWindowMemory` |\n",
    "| **LangChain Integration** | âŒ Manual conversion | âœ… Native |\n",
    "| **Metadata Storage** | âœ… Tool calls, etc. | âš ï¸ Limited |\n",
    "| **Customization** | âœ… Full control | âš ï¸ Less flexible |\n",
    "\n",
    "### Recommendation:\n",
    "- **Use LangChain** if you're building a full LangChain agent with chains/tools\n",
    "- **Use Custom** if you need TTL, context extraction, or custom features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4c928f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š MongoDB Collections Summary:\n",
      "============================================================\n",
      "  âœ… agent_memory: 1 documents\n",
      "  âœ… langchain_chat_history: 6 documents\n",
      "  âœ… langchain_conversations: 6 documents\n",
      "\n",
      "============================================================\n",
      "ğŸ‰ Agent Memory Demo Complete!\n",
      "============================================================\n",
      "\n",
      "You now have two options for adding memory to your agent:\n",
      "\n",
      "1. CUSTOM AgentMemory (Section 2-7):\n",
      "   - Full control over schema\n",
      "   - Built-in TTL expiration\n",
      "   - Context extraction (entities, topics)\n",
      "   - Copy class to: app/api/tools/core/memory.py\n",
      "\n",
      "2. LANGCHAIN MongoDBChatMessageHistory (Section 8-10):\n",
      "   - Quick setup with pip install\n",
      "   - Native LangChain integration\n",
      "   - Works with RunnableWithMessageHistory\n",
      "   - Add to requirements: langchain-mongodb\n",
      "\n",
      "Choose based on your needs! ğŸš€\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check all memory collections created\n",
    "print(\"ğŸ“Š MongoDB Collections Summary:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for coll_name in [\"agent_memory\", \"langchain_chat_history\", \"langchain_conversations\"]:\n",
    "    if coll_name in db.list_collection_names():\n",
    "        count = db[coll_name].count_documents({})\n",
    "        print(f\"  âœ… {coll_name}: {count} documents\")\n",
    "    else:\n",
    "        print(f\"  âŒ {coll_name}: not found\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ‰ Agent Memory Demo Complete!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\"\"\n",
    "You now have two options for adding memory to your agent:\n",
    "\n",
    "1. CUSTOM AgentMemory (Section 2-7):\n",
    "   - Full control over schema\n",
    "   - Built-in TTL expiration\n",
    "   - Context extraction (entities, topics)\n",
    "   - Copy class to: app/api/tools/core/memory.py\n",
    "\n",
    "2. LANGCHAIN MongoDBChatMessageHistory (Section 8-10):\n",
    "   - Quick setup with pip install\n",
    "   - Native LangChain integration\n",
    "   - Works with RunnableWithMessageHistory\n",
    "   - Add to requirements: langchain-mongodb\n",
    "\n",
    "Choose based on your needs! ğŸš€\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997d440f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ğŸ¦œğŸ”— Part 2: LangChain Agent with Tools & Memory\n",
    "\n",
    "Now let's build a complete LangChain agent that:\n",
    "1. **Uses all existing tools** (semantic search, expert finder, jargon buster, summarizer, meeting scheduler)\n",
    "2. **Has short-term memory** per user via MongoDB\n",
    "3. **Exposes as a FastAPI endpoint**\n",
    "\n",
    "## Architecture\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                         LangChain Agent System                               â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                              â”‚\n",
    "â”‚  User Request â”€â”€â–º FastAPI â”€â”€â–º LangChain Agent â”€â”€â–º Tool Execution            â”‚\n",
    "â”‚       â”‚              â”‚              â”‚                   â”‚                   â”‚\n",
    "â”‚       â”‚              â”‚              â–¼                   â”‚                   â”‚\n",
    "â”‚       â”‚              â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚                   â”‚\n",
    "â”‚       â”‚              â”‚    â”‚   Groq LLM      â”‚          â”‚                   â”‚\n",
    "â”‚       â”‚              â”‚    â”‚  (llama-4)      â”‚          â”‚                   â”‚\n",
    "â”‚       â”‚              â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚                   â”‚\n",
    "â”‚       â”‚              â”‚             â”‚                    â”‚                   â”‚\n",
    "â”‚       â”‚              â–¼             â–¼                    â–¼                   â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚\n",
    "â”‚  â”‚                    MongoDB Collections                              â”‚    â”‚\n",
    "â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”‚\n",
    "â”‚  â”‚ agent_memory â”‚   messages   â”‚    users     â”‚ message_embeddings   â”‚    â”‚\n",
    "â”‚  â”‚  (sessions)  â”‚              â”‚              â”‚   (vector search)    â”‚    â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚\n",
    "â”‚                                                                              â”‚\n",
    "â”‚  Available Tools:                                                           â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚\n",
    "â”‚  â”‚ semantic   â”‚ â”‚ find       â”‚ â”‚ jargon     â”‚ â”‚ summarize  â”‚              â”‚\n",
    "â”‚  â”‚ search     â”‚ â”‚ experts    â”‚ â”‚ buster     â”‚ â”‚ channel    â”‚              â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚\n",
    "â”‚  â”‚ schedule   â”‚ â”‚ find       â”‚ â”‚ get channelâ”‚                              â”‚\n",
    "â”‚  â”‚ meeting    â”‚ â”‚ users      â”‚ â”‚ info       â”‚                              â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ce89f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… LangChain agent packages installed!\n"
     ]
    }
   ],
   "source": [
    "# Install additional LangChain packages for agents\n",
    "import subprocess\n",
    "subprocess.run([\"pip\", \"install\", \"-q\", \"langchain\", \"langgraph\"], check=True)\n",
    "print(\"âœ… LangChain agent packages installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c35196",
   "metadata": {},
   "source": [
    "## 12. Define LangChain Tools from Existing Functions\n",
    "\n",
    "We'll wrap your existing tool functions as LangChain tools using the `@tool` decorator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc0f6cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Database: Connected to MongoDB\n",
      "ğŸ“¦ Database: Loading embedding model...\n",
      "âœ… Database: Embedding model loaded\n",
      "âœ… Database: Groq client initialized\n",
      "âœ… Imported all existing tool functions\n",
      "ğŸ“š Available: search_vector_db, find_users, find_experts_tool, jargon_buster_tool, summarize_tool, schedule_meeting_tool\n"
     ]
    }
   ],
   "source": [
    "# Install missing dependencies first\n",
    "import subprocess\n",
    "subprocess.run([\"pip\", \"install\", \"-q\", \"sentence-transformers\", \"groq\", \"google-auth\", \"google-auth-oauthlib\", \"google-api-python-client\"], check=True)\n",
    "\n",
    "# Add parent directory to import existing tools\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath(\"../app/api/tools\"))\n",
    "\n",
    "# Import existing tool functions\n",
    "from core.data_tools import (\n",
    "    search_vector_db, \n",
    "    find_users, \n",
    "    get_user_scope,\n",
    "    get_channel_info,\n",
    "    get_channel_members,\n",
    "    get_user_channels,\n",
    "    find_experts_in_db\n",
    ")\n",
    "from core.expert_tools import find_experts_tool\n",
    "from core.jargon_tools import jargon_buster_tool\n",
    "from core.summarizer_tools import summarize_tool\n",
    "from core.meeting_tools import schedule_meeting_tool\n",
    "from core.db import db_instance\n",
    "\n",
    "# Initialize database\n",
    "db_instance.initialize()\n",
    "\n",
    "print(\"âœ… Imported all existing tool functions\")\n",
    "print(f\"ğŸ“š Available: search_vector_db, find_users, find_experts_tool, jargon_buster_tool, summarize_tool, schedule_meeting_tool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2d331c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Created 6 LangChain tools:\n",
      "   - semantic_search: Search for past Slack messages using semantic/vector search....\n",
      "   - find_experts: Find people who are experts on a specific topic based on the...\n",
      "   - explain_jargon: Explain internal company jargon, acronyms, or technical term...\n",
      "   - summarize_channel: Summarize recent messages in a Slack channel.\n",
      "Use this when ...\n",
      "   - schedule_zoom_meeting: Schedule a Zoom meeting and send invitations.\n",
      "Use this when ...\n",
      "   - find_user_info: Find information about a user/colleague by name.\n",
      "Use this wh...\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "from typing import Optional, List\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# We'll use a context variable to pass user_id to tools\n",
    "# This is a common pattern in LangChain\n",
    "_current_user_id: str = None\n",
    "\n",
    "def set_current_user(user_id: str):\n",
    "    \"\"\"Set the current user context for tool execution.\"\"\"\n",
    "    global _current_user_id\n",
    "    _current_user_id = user_id\n",
    "\n",
    "def get_current_user() -> str:\n",
    "    \"\"\"Get the current user context.\"\"\"\n",
    "    return _current_user_id or \"unknown\"\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# LANGCHAIN TOOLS\n",
    "# =============================================================================\n",
    "\n",
    "@tool\n",
    "def semantic_search(query: str, top_k: int = 5) -> str:\n",
    "    \"\"\"\n",
    "    Search for past Slack messages using semantic/vector search.\n",
    "    Use this when the user wants to find messages about a specific topic,\n",
    "    or asks \"what was said about X\" or \"find messages about Y\".\n",
    "    \n",
    "    Args:\n",
    "        query: The search query (what to look for)\n",
    "        top_k: Number of results to return (default 5)\n",
    "    \n",
    "    Returns:\n",
    "        A summary of matching messages\n",
    "    \"\"\"\n",
    "    user_id = get_current_user()\n",
    "    scope = get_user_scope(user_id)\n",
    "    scope_channels = scope.get(\"channels\", [])\n",
    "    \n",
    "    if not scope_channels:\n",
    "        return \"You don't have access to any channels to search.\"\n",
    "    \n",
    "    result = search_vector_db(query, scope_channels, top_k)\n",
    "    \n",
    "    if result.get(\"error\"):\n",
    "        return f\"Search failed: {result.get('message', 'Unknown error')}\"\n",
    "    \n",
    "    results = result.get(\"results\", [])\n",
    "    if not results:\n",
    "        return f\"No messages found matching '{query}'.\"\n",
    "    \n",
    "    # Format results\n",
    "    output = f\"Found {len(results)} messages about '{query}':\\n\\n\"\n",
    "    for i, msg in enumerate(results, 1):\n",
    "        output += f\"{i}. **{msg.get('author_name', 'Unknown')}** in #{msg.get('channel_name', 'unknown')}:\\n\"\n",
    "        output += f\"   \\\"{msg.get('text', '')[:150]}...\\\"\\n\\n\"\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n",
    "@tool\n",
    "def find_experts(topic: str, top_k: int = 3) -> str:\n",
    "    \"\"\"\n",
    "    Find people who are experts on a specific topic based on their Slack messages.\n",
    "    Use this when the user asks \"who knows about X\" or \"find an expert in Y\".\n",
    "    \n",
    "    Args:\n",
    "        topic: The topic to find experts on\n",
    "        top_k: Number of experts to return (default 3)\n",
    "    \n",
    "    Returns:\n",
    "        A list of experts with their expertise level\n",
    "    \"\"\"\n",
    "    user_id = get_current_user()\n",
    "    result = find_experts_tool(topic, user_id, top_k)\n",
    "    \n",
    "    if not result.get(\"success\"):\n",
    "        return f\"Failed to find experts: {result.get('message', 'Unknown error')}\"\n",
    "    \n",
    "    experts = result.get(\"experts\", [])\n",
    "    if not experts:\n",
    "        return f\"No experts found for topic '{topic}'.\"\n",
    "    \n",
    "    output = f\"Found {len(experts)} expert(s) on '{topic}':\\n\\n\"\n",
    "    for i, expert in enumerate(experts, 1):\n",
    "        output += f\"{i}. **{expert.get('display_name', 'Unknown')}**\\n\"\n",
    "        output += f\"   - Relevance: {expert.get('relevance_score', 0):.2f}\\n\"\n",
    "        output += f\"   - Messages on topic: {expert.get('message_count', 0)}\\n\"\n",
    "        if expert.get('email'):\n",
    "            output += f\"   - Email: {expert.get('email')}\\n\"\n",
    "        output += \"\\n\"\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n",
    "@tool\n",
    "def explain_jargon(term: str, context: str = \"\") -> str:\n",
    "    \"\"\"\n",
    "    Explain internal company jargon, acronyms, or technical terms.\n",
    "    Use this when the user asks \"what does X mean\" or \"explain Y\".\n",
    "    \n",
    "    Args:\n",
    "        term: The jargon term or acronym to explain\n",
    "        context: Optional context about where the term was used\n",
    "    \n",
    "    Returns:\n",
    "        An explanation of the term\n",
    "    \"\"\"\n",
    "    user_id = get_current_user()\n",
    "    result = jargon_buster_tool(term, context, user_id)\n",
    "    \n",
    "    if not result.get(\"success\"):\n",
    "        return f\"Failed to explain term: {result.get('message', 'Unknown error')}\"\n",
    "    \n",
    "    output = f\"**{result.get('term', term)}**\\n\\n\"\n",
    "    output += f\"{result.get('explanation', 'No explanation available.')}\\n\\n\"\n",
    "    output += f\"_Source: {result.get('source', 'Unknown')}_\"\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n",
    "@tool\n",
    "def summarize_channel(channel_name: str, limit: int = 50) -> str:\n",
    "    \"\"\"\n",
    "    Summarize recent messages in a Slack channel.\n",
    "    Use this when the user asks to \"summarize #channel\" or \"what's happening in channel\".\n",
    "    Use channel_name='all' to summarize all accessible channels.\n",
    "    \n",
    "    Args:\n",
    "        channel_name: The channel name (without #) or 'all' for all channels\n",
    "        limit: Number of messages to include (default 50)\n",
    "    \n",
    "    Returns:\n",
    "        A summary of the channel conversation\n",
    "    \"\"\"\n",
    "    user_id = get_current_user()\n",
    "    result = summarize_tool(channel_name, user_id, limit)\n",
    "    \n",
    "    if not result.get(\"success\"):\n",
    "        return f\"Failed to summarize: {result.get('message', 'Unknown error')}\"\n",
    "    \n",
    "    output = f\"## Summary of #{result.get('channel_name', channel_name)}\\n\\n\"\n",
    "    output += f\"_Based on {result.get('message_count', 0)} messages_\\n\\n\"\n",
    "    output += result.get(\"summary\", \"No summary available.\")\n",
    "    \n",
    "    if result.get(\"highlights\"):\n",
    "        output += \"\\n\\n### Key Points:\\n\"\n",
    "        for h in result.get(\"highlights\", [])[:5]:\n",
    "            output += f\"- {h}\\n\"\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n",
    "@tool\n",
    "def schedule_zoom_meeting(\n",
    "    topic: str,\n",
    "    participant_names: str,\n",
    "    duration_minutes: int = 60,\n",
    "    start_time: str = \"\"\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Schedule a Zoom meeting and send invitations.\n",
    "    Use this when the user wants to \"schedule a meeting\" or \"set up a call\".\n",
    "    \n",
    "    Args:\n",
    "        topic: Meeting topic/title\n",
    "        participant_names: Comma-separated list of participant names (e.g., \"Alice, Bob, Charlie\")\n",
    "        duration_minutes: Meeting duration in minutes (default 60)\n",
    "        start_time: ISO 8601 start time (optional, defaults to 5 minutes from now)\n",
    "    \n",
    "    Returns:\n",
    "        Meeting details and invitation status\n",
    "    \"\"\"\n",
    "    from datetime import datetime, timedelta\n",
    "    \n",
    "    user_id = get_current_user()\n",
    "    \n",
    "    # Parse participant names\n",
    "    names = [n.strip() for n in participant_names.split(\",\") if n.strip()]\n",
    "    \n",
    "    if not names:\n",
    "        return \"Please specify who you want to meet with.\"\n",
    "    \n",
    "    # Default start time if not provided\n",
    "    if not start_time:\n",
    "        start_time = (datetime.utcnow() + timedelta(minutes=5)).strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "    \n",
    "    result = schedule_meeting_tool(\n",
    "        topic=topic,\n",
    "        start_time=start_time,\n",
    "        duration_minutes=duration_minutes,\n",
    "        requesting_user_id=user_id,\n",
    "        participant_emails=[],\n",
    "        participant_names=names\n",
    "    )\n",
    "    \n",
    "    if not result.get(\"success\"):\n",
    "        return f\"Failed to schedule meeting: {result.get('message', 'Unknown error')}\"\n",
    "    \n",
    "    meeting = result.get(\"meeting\", {})\n",
    "    email_status = result.get(\"email_status\", {})\n",
    "    \n",
    "    output = f\"## Meeting Scheduled! ğŸ‰\\n\\n\"\n",
    "    output += f\"**Topic:** {meeting.get('topic', topic)}\\n\"\n",
    "    output += f\"**Join URL:** {meeting.get('join_url', 'N/A')}\\n\"\n",
    "    output += f\"**Meeting ID:** {meeting.get('meeting_id', 'N/A')}\\n\"\n",
    "    output += f\"**Password:** {meeting.get('password', 'N/A')}\\n\"\n",
    "    output += f\"**Start Time:** {meeting.get('start_time', start_time)}\\n\"\n",
    "    output += f\"**Duration:** {meeting.get('duration', duration_minutes)} minutes\\n\\n\"\n",
    "    output += f\"**Invitations:** Sent to {email_status.get('successful', 0)}/{email_status.get('total', 0)} participants\"\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n",
    "@tool  \n",
    "def find_user_info(name: str) -> str:\n",
    "    \"\"\"\n",
    "    Find information about a user/colleague by name.\n",
    "    Use this when the user asks about someone like \"who is X\" or \"tell me about Y\".\n",
    "    \n",
    "    Args:\n",
    "        name: The name of the person to look up\n",
    "    \n",
    "    Returns:\n",
    "        User profile information\n",
    "    \"\"\"\n",
    "    user_id = get_current_user()\n",
    "    scope = get_user_scope(user_id)\n",
    "    scope_user_ids = scope.get(\"user_ids\", [])\n",
    "    \n",
    "    result = find_users(name, scope_user_ids)\n",
    "    users = result.get(\"users\", [])\n",
    "    \n",
    "    if not users:\n",
    "        return f\"No user found matching '{name}'.\"\n",
    "    \n",
    "    output = f\"Found {len(users)} user(s) matching '{name}':\\n\\n\"\n",
    "    for user in users:\n",
    "        output += f\"**{user.get('display_name', 'Unknown')}**\\n\"\n",
    "        if user.get('email'):\n",
    "            output += f\"- Email: {user.get('email')}\\n\"\n",
    "        if user.get('username'):\n",
    "            output += f\"- Username: @{user.get('username')}\\n\"\n",
    "        output += \"\\n\"\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n",
    "# Collect all tools\n",
    "all_tools = [\n",
    "    semantic_search,\n",
    "    find_experts,\n",
    "    explain_jargon,\n",
    "    summarize_channel,\n",
    "    schedule_zoom_meeting,\n",
    "    find_user_info\n",
    "]\n",
    "\n",
    "print(f\"âœ… Created {len(all_tools)} LangChain tools:\")\n",
    "for t in all_tools:\n",
    "    print(f\"   - {t.name}: {t.description[:60]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71dcfd4",
   "metadata": {},
   "source": [
    "## 13. Create the LangChain Agent with Memory\n",
    "\n",
    "Now we'll create a LangChain agent that:\n",
    "1. Uses Groq LLM for reasoning\n",
    "2. Has access to all our tools\n",
    "3. Stores conversation history per user in MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f9ebdc3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… LangGraph ReAct Agent created with all tools!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_113537/2256422715.py:39: LangGraphDeprecatedSinceV10: create_react_agent has been moved to `langchain.agents`. Please update your import to `from langchain.agents import create_agent`. Deprecated in LangGraph V1.0 to be removed in V2.0.\n",
      "  agent_graph = create_react_agent(\n"
     ]
    }
   ],
   "source": [
    "# Use langgraph for the agent (more modern approach)\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_mongodb import MongoDBChatMessageHistory\n",
    "\n",
    "# =============================================================================\n",
    "# AGENT SYSTEM PROMPT\n",
    "# =============================================================================\n",
    "AGENT_SYSTEM_MESSAGE = \"\"\"You are ConnectBest AI, a helpful Slack assistant for enterprise teams.\n",
    "\n",
    "You have access to tools to help users:\n",
    "1. **semantic_search** - Search past Slack messages by topic\n",
    "2. **find_experts** - Find people who know about specific topics\n",
    "3. **explain_jargon** - Explain company jargon, acronyms, and technical terms\n",
    "4. **summarize_channel** - Summarize channel conversations  \n",
    "5. **schedule_zoom_meeting** - Schedule Zoom meetings with colleagues\n",
    "6. **find_user_info** - Look up information about colleagues\n",
    "\n",
    "Guidelines:\n",
    "- Be concise and helpful\n",
    "- Use tools when appropriate - don't guess at information\n",
    "- Reference conversation history to understand context (e.g., if user says \"her\", check who was mentioned before)\n",
    "- Format responses nicely with markdown when appropriate\n",
    "- If you can't help with something, explain why\"\"\"\n",
    "\n",
    "# =============================================================================\n",
    "# CREATE THE AGENT\n",
    "# =============================================================================\n",
    "\n",
    "# Initialize LLM\n",
    "agent_llm = ChatGroq(\n",
    "    api_key=GROQ_API_KEY,\n",
    "    model_name=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.3,\n",
    ")\n",
    "\n",
    "# Create the agent using langgraph with the correct 'prompt' parameter\n",
    "agent_graph = create_react_agent(\n",
    "    agent_llm, \n",
    "    all_tools,\n",
    "    prompt=AGENT_SYSTEM_MESSAGE  # Changed from state_modifier to prompt\n",
    ")\n",
    "\n",
    "print(\"âœ… LangGraph ReAct Agent created with all tools!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1149283",
   "metadata": {},
   "source": [
    "### Step 5: Run Agent with Memory\n",
    "\n",
    "Now let's create a helper function to run the agent with MongoDB memory per user session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "06065f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Agent runner with MongoDB memory created!\n",
      "   - Sessions stored in: connectbest_chat.agent_conversations\n",
      "   - Session TTL: 24 hours\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# AGENT RUNNER WITH MONGODB MEMORY\n",
    "# =============================================================================\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from typing import Optional\n",
    "import uuid\n",
    "\n",
    "# Memory saver for conversation checkpoints\n",
    "memory_saver = MemorySaver()\n",
    "\n",
    "# We'll also use MongoDB to persist the memory for longer-term storage\n",
    "AGENT_MEMORY_COLLECTION = \"agent_conversations\"\n",
    "\n",
    "def get_or_create_session(user_id: str) -> str:\n",
    "    \"\"\"Get or create a session ID for a user\"\"\"\n",
    "    db = client[DATABASE_NAME]\n",
    "    collection = db[AGENT_MEMORY_COLLECTION]\n",
    "    \n",
    "    # Find active session (created in last 24 hours)\n",
    "    existing = collection.find_one({\n",
    "        \"user_id\": user_id,\n",
    "        \"created_at\": {\"$gte\": datetime.now() - timedelta(hours=24)}\n",
    "    }, sort=[(\"created_at\", DESCENDING)])\n",
    "    \n",
    "    if existing:\n",
    "        return existing[\"session_id\"]\n",
    "    \n",
    "    # Create new session\n",
    "    session_id = str(uuid.uuid4())\n",
    "    collection.insert_one({\n",
    "        \"user_id\": user_id,\n",
    "        \"session_id\": session_id,\n",
    "        \"created_at\": datetime.now(),\n",
    "        \"messages\": []\n",
    "    })\n",
    "    return session_id\n",
    "\n",
    "\n",
    "def save_message_to_mongo(user_id: str, session_id: str, role: str, content: str):\n",
    "    \"\"\"Save a message to MongoDB for persistence\"\"\"\n",
    "    db = client[DATABASE_NAME]\n",
    "    collection = db[AGENT_MEMORY_COLLECTION]\n",
    "    \n",
    "    collection.update_one(\n",
    "        {\"session_id\": session_id},\n",
    "        {\n",
    "            \"$push\": {\n",
    "                \"messages\": {\n",
    "                    \"role\": role,\n",
    "                    \"content\": content,\n",
    "                    \"timestamp\": datetime.now()\n",
    "                }\n",
    "            },\n",
    "            \"$set\": {\"updated_at\": datetime.now()}\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "def load_messages_from_mongo(session_id: str) -> list:\n",
    "    \"\"\"Load message history from MongoDB\"\"\"\n",
    "    db = client[DATABASE_NAME]\n",
    "    collection = db[AGENT_MEMORY_COLLECTION]\n",
    "    \n",
    "    session = collection.find_one({\"session_id\": session_id})\n",
    "    if not session:\n",
    "        return []\n",
    "    \n",
    "    messages = []\n",
    "    for msg in session.get(\"messages\", []):\n",
    "        if msg[\"role\"] == \"user\":\n",
    "            messages.append(HumanMessage(content=msg[\"content\"]))\n",
    "        else:\n",
    "            messages.append(AIMessage(content=msg[\"content\"]))\n",
    "    return messages\n",
    "\n",
    "\n",
    "async def run_agent(user_message: str, user_id: str, include_history: bool = True) -> str:\n",
    "    \"\"\"\n",
    "    Run the LangGraph agent with user's message and memory.\n",
    "    \n",
    "    Args:\n",
    "        user_message: The user's input message\n",
    "        user_id: The user ID (for session management)\n",
    "        include_history: Whether to include conversation history\n",
    "        \n",
    "    Returns:\n",
    "        The agent's response as a string\n",
    "    \"\"\"\n",
    "    # Get or create session for this user\n",
    "    session_id = get_or_create_session(user_id)\n",
    "    \n",
    "    # Load previous messages if including history\n",
    "    previous_messages = []\n",
    "    if include_history:\n",
    "        previous_messages = load_messages_from_mongo(session_id)\n",
    "    \n",
    "    # Build messages list with system message and history\n",
    "    messages = [SystemMessage(content=AGENT_SYSTEM_MESSAGE)]\n",
    "    messages.extend(previous_messages)\n",
    "    messages.append(HumanMessage(content=user_message))\n",
    "    \n",
    "    # Create config for this thread\n",
    "    config = {\"configurable\": {\"thread_id\": session_id}}\n",
    "    \n",
    "    # Run the agent\n",
    "    result = await agent_graph.ainvoke({\"messages\": messages}, config=config)\n",
    "    \n",
    "    # Extract the final response\n",
    "    final_message = result[\"messages\"][-1]\n",
    "    response_content = final_message.content\n",
    "    \n",
    "    # Save to MongoDB for persistence\n",
    "    save_message_to_mongo(user_id, session_id, \"user\", user_message)\n",
    "    save_message_to_mongo(user_id, session_id, \"assistant\", response_content)\n",
    "    \n",
    "    return response_content\n",
    "\n",
    "\n",
    "# Synchronous wrapper for easier testing\n",
    "def run_agent_sync(user_message: str, user_id: str, include_history: bool = True) -> str:\n",
    "    \"\"\"Synchronous wrapper for run_agent\"\"\"\n",
    "    import asyncio\n",
    "    return asyncio.run(run_agent(user_message, user_id, include_history))\n",
    "\n",
    "\n",
    "print(\"âœ… Agent runner with MongoDB memory created!\")\n",
    "print(f\"   - Sessions stored in: {DATABASE_NAME}.{AGENT_MEMORY_COLLECTION}\")\n",
    "print(f\"   - Session TTL: 24 hours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bc9f36",
   "metadata": {},
   "source": [
    "### Step 6: Test the Agent\n",
    "\n",
    "Let's test the agent with multiple queries to see how it uses tools and maintains context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9061a137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª Testing with user: 758494dd-09f7-4c8e-908a-6366388ad540\n",
      "\n",
      "ğŸ‘¤ User: Search for any messages about postgres\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': 'tool call validation failed: parameters for tool semantic_search did not match schema: errors: [`/top_k`: expected integer, but got string]', 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '[\\n  {\\n    \"name\": \"semantic_search\",\\n    \"parameters\": {\\n      \"query\": \"postgres\",\\n      \"top_k\": \"5\"\\n    }\\n  }\\n]'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mğŸ‘¤ User: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery1\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m50\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m response1 = \u001b[38;5;28;01mawait\u001b[39;00m run_agent(query1, DEMO_USER_ID)\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mğŸ¤– Agent: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse1\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 107\u001b[39m, in \u001b[36mrun_agent\u001b[39m\u001b[34m(user_message, user_id, include_history)\u001b[39m\n\u001b[32m    104\u001b[39m config = {\u001b[33m\"\u001b[39m\u001b[33mconfigurable\u001b[39m\u001b[33m\"\u001b[39m: {\u001b[33m\"\u001b[39m\u001b[33mthread_id\u001b[39m\u001b[33m\"\u001b[39m: session_id}}\n\u001b[32m    106\u001b[39m \u001b[38;5;66;03m# Run the agent\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m agent_graph.ainvoke({\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: messages}, config=config)\n\u001b[32m    109\u001b[39m \u001b[38;5;66;03m# Extract the final response\u001b[39;00m\n\u001b[32m    110\u001b[39m final_message = result[\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m][-\u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/slack_project/chat/.venv/lib/python3.13/site-packages/langgraph/pregel/main.py:3158\u001b[39m, in \u001b[36mPregel.ainvoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3155\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3156\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3158\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.astream(\n\u001b[32m   3159\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   3160\u001b[39m     config,\n\u001b[32m   3161\u001b[39m     context=context,\n\u001b[32m   3162\u001b[39m     stream_mode=[\u001b[33m\"\u001b[39m\u001b[33mupdates\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   3163\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode == \u001b[33m\"\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   3164\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m stream_mode,\n\u001b[32m   3165\u001b[39m     print_mode=print_mode,\n\u001b[32m   3166\u001b[39m     output_keys=output_keys,\n\u001b[32m   3167\u001b[39m     interrupt_before=interrupt_before,\n\u001b[32m   3168\u001b[39m     interrupt_after=interrupt_after,\n\u001b[32m   3169\u001b[39m     durability=durability,\n\u001b[32m   3170\u001b[39m     **kwargs,\n\u001b[32m   3171\u001b[39m ):\n\u001b[32m   3172\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode == \u001b[33m\"\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   3173\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(chunk) == \u001b[32m2\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/slack_project/chat/.venv/lib/python3.13/site-packages/langgraph/pregel/main.py:2971\u001b[39m, in \u001b[36mPregel.astream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2969\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m loop.amatch_cached_writes():\n\u001b[32m   2970\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2971\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner.atick(\n\u001b[32m   2972\u001b[39m     [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m loop.tasks.values() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t.writes],\n\u001b[32m   2973\u001b[39m     timeout=\u001b[38;5;28mself\u001b[39m.step_timeout,\n\u001b[32m   2974\u001b[39m     get_waiter=get_waiter,\n\u001b[32m   2975\u001b[39m     schedule_task=loop.aaccept_push,\n\u001b[32m   2976\u001b[39m ):\n\u001b[32m   2977\u001b[39m     \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[32m   2978\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m _output(\n\u001b[32m   2979\u001b[39m         stream_mode,\n\u001b[32m   2980\u001b[39m         print_mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2983\u001b[39m         asyncio.QueueEmpty,\n\u001b[32m   2984\u001b[39m     ):\n\u001b[32m   2985\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m o\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/slack_project/chat/.venv/lib/python3.13/site-packages/langgraph/pregel/_runner.py:304\u001b[39m, in \u001b[36mPregelRunner.atick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    302\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    303\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m304\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m arun_with_retry(\n\u001b[32m    305\u001b[39m         t,\n\u001b[32m    306\u001b[39m         retry_policy,\n\u001b[32m    307\u001b[39m         stream=\u001b[38;5;28mself\u001b[39m.use_astream,\n\u001b[32m    308\u001b[39m         configurable={\n\u001b[32m    309\u001b[39m             CONFIG_KEY_CALL: partial(\n\u001b[32m    310\u001b[39m                 _acall,\n\u001b[32m    311\u001b[39m                 weakref.ref(t),\n\u001b[32m    312\u001b[39m                 stream=\u001b[38;5;28mself\u001b[39m.use_astream,\n\u001b[32m    313\u001b[39m                 retry_policy=retry_policy,\n\u001b[32m    314\u001b[39m                 futures=weakref.ref(futures),\n\u001b[32m    315\u001b[39m                 schedule_task=schedule_task,\n\u001b[32m    316\u001b[39m                 submit=\u001b[38;5;28mself\u001b[39m.submit,\n\u001b[32m    317\u001b[39m                 loop=loop,\n\u001b[32m    318\u001b[39m             ),\n\u001b[32m    319\u001b[39m         },\n\u001b[32m    320\u001b[39m     )\n\u001b[32m    321\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    322\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/slack_project/chat/.venv/lib/python3.13/site-packages/langgraph/pregel/_retry.py:137\u001b[39m, in \u001b[36marun_with_retry\u001b[39m\u001b[34m(task, retry_policy, stream, match_cached_writes, configurable)\u001b[39m\n\u001b[32m    135\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    136\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m task.proc.ainvoke(task.input, config)\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    139\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/slack_project/chat/.venv/lib/python3.13/site-packages/langgraph/_internal/_runnable.py:705\u001b[39m, in \u001b[36mRunnableSeq.ainvoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    703\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    704\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m705\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.create_task(\n\u001b[32m    706\u001b[39m             step.ainvoke(\u001b[38;5;28minput\u001b[39m, config, **kwargs), context=context\n\u001b[32m    707\u001b[39m         )\n\u001b[32m    708\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    709\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[38;5;28;01mawait\u001b[39;00m step.ainvoke(\u001b[38;5;28minput\u001b[39m, config, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/slack_project/chat/.venv/lib/python3.13/site-packages/langgraph/_internal/_runnable.py:464\u001b[39m, in \u001b[36mRunnableCallable.ainvoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    462\u001b[39m         run = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    463\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m464\u001b[39m         ret = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.create_task(coro, context=context)\n\u001b[32m    465\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    466\u001b[39m     ret = \u001b[38;5;28;01mawait\u001b[39;00m coro\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/slack_project/chat/.venv/lib/python3.13/site-packages/langgraph/prebuilt/chat_agent_executor.py:696\u001b[39m, in \u001b[36mcreate_react_agent.<locals>.acall_model\u001b[39m\u001b[34m(state, runtime, config)\u001b[39m\n\u001b[32m    694\u001b[39m     response = cast(AIMessage, \u001b[38;5;28;01mawait\u001b[39;00m dynamic_model.ainvoke(model_input, config))  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m696\u001b[39m     response = cast(AIMessage, \u001b[38;5;28;01mawait\u001b[39;00m static_model.ainvoke(model_input, config))  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[32m    698\u001b[39m \u001b[38;5;66;03m# add agent name to the AIMessage\u001b[39;00m\n\u001b[32m    699\u001b[39m response.name = name\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/slack_project/chat/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py:3169\u001b[39m, in \u001b[36mRunnableSequence.ainvoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3167\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3168\u001b[39m                 part = functools.partial(step.ainvoke, input_, config)\n\u001b[32m-> \u001b[39m\u001b[32m3169\u001b[39m             input_ = \u001b[38;5;28;01mawait\u001b[39;00m coro_with_context(part(), context, create_task=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   3170\u001b[39m     \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3171\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/slack_project/chat/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py:5547\u001b[39m, in \u001b[36mRunnableBindingBase.ainvoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5540\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5541\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mainvoke\u001b[39m(\n\u001b[32m   5542\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5545\u001b[39m     **kwargs: Any | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   5546\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5547\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.bound.ainvoke(\n\u001b[32m   5548\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   5549\u001b[39m         \u001b[38;5;28mself\u001b[39m._merge_configs(config),\n\u001b[32m   5550\u001b[39m         **{**\u001b[38;5;28mself\u001b[39m.kwargs, **kwargs},\n\u001b[32m   5551\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/slack_project/chat/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:421\u001b[39m, in \u001b[36mBaseChatModel.ainvoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    411\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    412\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mainvoke\u001b[39m(\n\u001b[32m    413\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    418\u001b[39m     **kwargs: Any,\n\u001b[32m    419\u001b[39m ) -> AIMessage:\n\u001b[32m    420\u001b[39m     config = ensure_config(config)\n\u001b[32m--> \u001b[39m\u001b[32m421\u001b[39m     llm_result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.agenerate_prompt(\n\u001b[32m    422\u001b[39m         [\u001b[38;5;28mself\u001b[39m._convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[32m    423\u001b[39m         stop=stop,\n\u001b[32m    424\u001b[39m         callbacks=config.get(\u001b[33m\"\u001b[39m\u001b[33mcallbacks\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    425\u001b[39m         tags=config.get(\u001b[33m\"\u001b[39m\u001b[33mtags\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    426\u001b[39m         metadata=config.get(\u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    427\u001b[39m         run_name=config.get(\u001b[33m\"\u001b[39m\u001b[33mrun_name\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    428\u001b[39m         run_id=config.pop(\u001b[33m\"\u001b[39m\u001b[33mrun_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m    429\u001b[39m         **kwargs,\n\u001b[32m    430\u001b[39m     )\n\u001b[32m    431\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    432\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAIMessage\u001b[39m\u001b[33m\"\u001b[39m, cast(\u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m, llm_result.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m]).message\n\u001b[32m    433\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/slack_project/chat/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:1128\u001b[39m, in \u001b[36mBaseChatModel.agenerate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1119\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1120\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34magenerate_prompt\u001b[39m(\n\u001b[32m   1121\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1125\u001b[39m     **kwargs: Any,\n\u001b[32m   1126\u001b[39m ) -> LLMResult:\n\u001b[32m   1127\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.agenerate(\n\u001b[32m   1129\u001b[39m         prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n\u001b[32m   1130\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/slack_project/chat/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:1086\u001b[39m, in \u001b[36mBaseChatModel.agenerate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m   1073\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[32m   1074\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(\n\u001b[32m   1075\u001b[39m             *[\n\u001b[32m   1076\u001b[39m                 run_manager.on_llm_end(\n\u001b[32m   (...)\u001b[39m\u001b[32m   1084\u001b[39m             ]\n\u001b[32m   1085\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1086\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions[\u001b[32m0\u001b[39m]\n\u001b[32m   1087\u001b[39m flattened_outputs = [\n\u001b[32m   1088\u001b[39m     LLMResult(generations=[res.generations], llm_output=res.llm_output)  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[32m   1089\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[32m   1090\u001b[39m ]\n\u001b[32m   1091\u001b[39m llm_output = \u001b[38;5;28mself\u001b[39m._combine_llm_outputs([res.llm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/slack_project/chat/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:1339\u001b[39m, in \u001b[36mBaseChatModel._agenerate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1337\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1338\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._agenerate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1339\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._agenerate(\n\u001b[32m   1340\u001b[39m         messages, stop=stop, run_manager=run_manager, **kwargs\n\u001b[32m   1341\u001b[39m     )\n\u001b[32m   1342\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1343\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._agenerate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/slack_project/chat/.venv/lib/python3.13/site-packages/langchain_groq/chat_models.py:611\u001b[39m, in \u001b[36mChatGroq._agenerate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    606\u001b[39m message_dicts, params = \u001b[38;5;28mself\u001b[39m._create_message_dicts(messages, stop)\n\u001b[32m    607\u001b[39m params = {\n\u001b[32m    608\u001b[39m     **params,\n\u001b[32m    609\u001b[39m     **kwargs,\n\u001b[32m    610\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m611\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.async_client.create(messages=message_dicts, **params)\n\u001b[32m    612\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_chat_result(response, params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/slack_project/chat/.venv/lib/python3.13/site-packages/groq/resources/chat/completions.py:941\u001b[39m, in \u001b[36mAsyncCompletions.create\u001b[39m\u001b[34m(self, messages, model, citation_options, compound_custom, disable_tool_validation, documents, exclude_domains, frequency_penalty, function_call, functions, include_domains, include_reasoning, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, n, parallel_tool_calls, presence_penalty, reasoning_effort, reasoning_format, response_format, search_settings, seed, service_tier, stop, store, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    721\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    722\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    723\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m    780\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = not_given,\n\u001b[32m    781\u001b[39m ) -> ChatCompletion | AsyncStream[ChatCompletionChunk]:\n\u001b[32m    782\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    783\u001b[39m \u001b[33;03m    Creates a model response for the given chat conversation.\u001b[39;00m\n\u001b[32m    784\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    939\u001b[39m \u001b[33;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[32m    940\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m941\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._post(\n\u001b[32m    942\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m/openai/v1/chat/completions\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    943\u001b[39m         body=\u001b[38;5;28;01mawait\u001b[39;00m async_maybe_transform(\n\u001b[32m    944\u001b[39m             {\n\u001b[32m    945\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: messages,\n\u001b[32m    946\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: model,\n\u001b[32m    947\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mcitation_options\u001b[39m\u001b[33m\"\u001b[39m: citation_options,\n\u001b[32m    948\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mcompound_custom\u001b[39m\u001b[33m\"\u001b[39m: compound_custom,\n\u001b[32m    949\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mdisable_tool_validation\u001b[39m\u001b[33m\"\u001b[39m: disable_tool_validation,\n\u001b[32m    950\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mdocuments\u001b[39m\u001b[33m\"\u001b[39m: documents,\n\u001b[32m    951\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mexclude_domains\u001b[39m\u001b[33m\"\u001b[39m: exclude_domains,\n\u001b[32m    952\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mfrequency_penalty\u001b[39m\u001b[33m\"\u001b[39m: frequency_penalty,\n\u001b[32m    953\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mfunction_call\u001b[39m\u001b[33m\"\u001b[39m: function_call,\n\u001b[32m    954\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mfunctions\u001b[39m\u001b[33m\"\u001b[39m: functions,\n\u001b[32m    955\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33minclude_domains\u001b[39m\u001b[33m\"\u001b[39m: include_domains,\n\u001b[32m    956\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33minclude_reasoning\u001b[39m\u001b[33m\"\u001b[39m: include_reasoning,\n\u001b[32m    957\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mlogit_bias\u001b[39m\u001b[33m\"\u001b[39m: logit_bias,\n\u001b[32m    958\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mlogprobs\u001b[39m\u001b[33m\"\u001b[39m: logprobs,\n\u001b[32m    959\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmax_completion_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_completion_tokens,\n\u001b[32m    960\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmax_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_tokens,\n\u001b[32m    961\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: metadata,\n\u001b[32m    962\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mn\u001b[39m\u001b[33m\"\u001b[39m: n,\n\u001b[32m    963\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mparallel_tool_calls\u001b[39m\u001b[33m\"\u001b[39m: parallel_tool_calls,\n\u001b[32m    964\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mpresence_penalty\u001b[39m\u001b[33m\"\u001b[39m: presence_penalty,\n\u001b[32m    965\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mreasoning_effort\u001b[39m\u001b[33m\"\u001b[39m: reasoning_effort,\n\u001b[32m    966\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mreasoning_format\u001b[39m\u001b[33m\"\u001b[39m: reasoning_format,\n\u001b[32m    967\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mresponse_format\u001b[39m\u001b[33m\"\u001b[39m: response_format,\n\u001b[32m    968\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33msearch_settings\u001b[39m\u001b[33m\"\u001b[39m: search_settings,\n\u001b[32m    969\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mseed\u001b[39m\u001b[33m\"\u001b[39m: seed,\n\u001b[32m    970\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mservice_tier\u001b[39m\u001b[33m\"\u001b[39m: service_tier,\n\u001b[32m    971\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstop\u001b[39m\u001b[33m\"\u001b[39m: stop,\n\u001b[32m    972\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstore\u001b[39m\u001b[33m\"\u001b[39m: store,\n\u001b[32m    973\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m: stream,\n\u001b[32m    974\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m\"\u001b[39m: temperature,\n\u001b[32m    975\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtool_choice\u001b[39m\u001b[33m\"\u001b[39m: tool_choice,\n\u001b[32m    976\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtools\u001b[39m\u001b[33m\"\u001b[39m: tools,\n\u001b[32m    977\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtop_logprobs\u001b[39m\u001b[33m\"\u001b[39m: top_logprobs,\n\u001b[32m    978\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtop_p\u001b[39m\u001b[33m\"\u001b[39m: top_p,\n\u001b[32m    979\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m: user,\n\u001b[32m    980\u001b[39m             },\n\u001b[32m    981\u001b[39m             completion_create_params.CompletionCreateParams,\n\u001b[32m    982\u001b[39m         ),\n\u001b[32m    983\u001b[39m         options=make_request_options(\n\u001b[32m    984\u001b[39m             extra_headers=extra_headers, extra_query=extra_query, extra_body=extra_body, timeout=timeout\n\u001b[32m    985\u001b[39m         ),\n\u001b[32m    986\u001b[39m         cast_to=ChatCompletion,\n\u001b[32m    987\u001b[39m         stream=stream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    988\u001b[39m         stream_cls=AsyncStream[ChatCompletionChunk],\n\u001b[32m    989\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/slack_project/chat/.venv/lib/python3.13/site-packages/groq/_base_client.py:1762\u001b[39m, in \u001b[36mAsyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1748\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1750\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1757\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_AsyncStreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1758\u001b[39m ) -> ResponseT | _AsyncStreamT:\n\u001b[32m   1759\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1760\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=\u001b[38;5;28;01mawait\u001b[39;00m async_to_httpx_files(files), **options\n\u001b[32m   1761\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/slack_project/chat/.venv/lib/python3.13/site-packages/groq/_base_client.py:1576\u001b[39m, in \u001b[36mAsyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1573\u001b[39m             \u001b[38;5;28;01mawait\u001b[39;00m err.response.aread()\n\u001b[32m   1575\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1576\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1578\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1580\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mBadRequestError\u001b[39m: Error code: 400 - {'error': {'message': 'tool call validation failed: parameters for tool semantic_search did not match schema: errors: [`/top_k`: expected integer, but got string]', 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '[\\n  {\\n    \"name\": \"semantic_search\",\\n    \"parameters\": {\\n      \"query\": \"postgres\",\\n      \"top_k\": \"5\"\\n    }\\n  }\\n]'}}",
      "During task with name 'agent' and id '861d5355-e607-95f4-fe40-811877d92519'"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# TEST THE AGENT - Query 1: Search for messages\n",
    "# =============================================================================\n",
    "import asyncio\n",
    "\n",
    "# Use a test user ID\n",
    "DEMO_USER_ID = \"758494dd-09f7-4c8e-908a-6366388ad540\"\n",
    "print(f\"ğŸ§ª Testing with user: {DEMO_USER_ID}\\n\")\n",
    "\n",
    "# First query - search for something\n",
    "query1 = \"Search for any messages about postgres\"\n",
    "print(f\"ğŸ‘¤ User: {query1}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "response1 = await run_agent(query1, DEMO_USER_ID)\n",
    "print(f\"ğŸ¤– Agent: {response1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ed2feff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ‘¤ User: Who are the experts in Python programming?\n",
      "--------------------------------------------------\n",
      "ğŸ¤– Agent: No experts found for topic 'Python programming'.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# TEST THE AGENT - Query 2: Find experts\n",
    "# =============================================================================\n",
    "\n",
    "query2 = \"Who are the experts in Python programming?\"\n",
    "print(f\"\\nğŸ‘¤ User: {query2}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "response2 = await run_agent(query2, DEMO_USER_ID)\n",
    "print(f\"ğŸ¤– Agent: {response2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bdb63cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ‘¤ User: What does API mean?\n",
      "--------------------------------------------------\n",
      "ğŸ¤– Agent: API stands for Application Programming Interface. It's a messenger between different software systems that allows them to communicate with each other. Think of it like ordering food at a restaurant, where the waiter acts as an intermediary between you and the kitchen. APIs are used in many areas, such as retrieving data from a website, sending information between apps, or integrating third-party services. They make it easier for different systems to work together seamlessly and are a fundamental part of modern software development.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# TEST THE AGENT - Query 3: Explain jargon  \n",
    "# =============================================================================\n",
    "\n",
    "query3 = \"What does API mean?\"\n",
    "print(f\"\\nğŸ‘¤ User: {query3}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "response3 = await run_agent(query3, DEMO_USER_ID)\n",
    "print(f\"ğŸ¤– Agent: {response3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "957e515e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ‘¤ User: Can you explain that in one sentence?\n",
      "--------------------------------------------------\n",
      "ğŸ¤– Agent: An API, or Application Programming Interface, is a messenger between different software systems that allows them to communicate with each other.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# TEST THE AGENT - Query 4: Memory test - follow-up question\n",
    "# =============================================================================\n",
    "\n",
    "query4 = \"Can you explain that in one sentence?\"  # This refers to the previous API explanation\n",
    "print(f\"\\nğŸ‘¤ User: {query4}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "response4 = await run_agent(query4, DEMO_USER_ID)\n",
    "print(f\"ğŸ¤– Agent: {response4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "95c468e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Session stored in MongoDB:\n",
      "============================================================\n",
      "User ID: 758494dd-09f7-4c8e-908a-6366388ad540\n",
      "Session ID: e759a265-77c4-4250-a01f-43981a04eb91\n",
      "Created: 2025-12-01 15:21:44.924000\n",
      "Messages stored: 10\n",
      "\n",
      "ğŸ“ Message History:\n",
      "------------------------------------------------------------\n",
      "1. ğŸ‘¤ [user]: Search for any messages about machine learning or AI\n",
      "2. ğŸ¤– [assistant]: I don't have access to any channels to search.\n",
      "3. ğŸ‘¤ [user]: Who are the experts in Python programming?\n",
      "4. ğŸ¤– [assistant]: No experts found for topic 'Python programming'.\n",
      "5. ğŸ‘¤ [user]: Who are the experts in Python programming?\n",
      "6. ğŸ¤– [assistant]: No experts found for topic 'Python programming'.\n",
      "7. ğŸ‘¤ [user]: What does API mean?\n",
      "8. ğŸ¤– [assistant]: API stands for Application Programming Interface. It's a messenger between different software system...\n",
      "9. ğŸ‘¤ [user]: Can you explain that in one sentence?\n",
      "10. ğŸ¤– [assistant]: An API, or Application Programming Interface, is a messenger between different software systems that...\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# VERIFY MEMORY STORED IN MONGODB\n",
    "# =============================================================================\n",
    "\n",
    "db = client[DATABASE_NAME]\n",
    "collection = db[AGENT_MEMORY_COLLECTION]\n",
    "\n",
    "# Find the session for our demo user\n",
    "session = collection.find_one({\"user_id\": DEMO_USER_ID})\n",
    "\n",
    "print(\"ğŸ“Š Session stored in MongoDB:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"User ID: {session['user_id']}\")\n",
    "print(f\"Session ID: {session['session_id']}\")\n",
    "print(f\"Created: {session['created_at']}\")\n",
    "print(f\"Messages stored: {len(session['messages'])}\")\n",
    "print()\n",
    "print(\"ğŸ“ Message History:\")\n",
    "print(\"-\" * 60)\n",
    "for i, msg in enumerate(session['messages'], 1):\n",
    "    role_icon = \"ğŸ‘¤\" if msg['role'] == 'user' else \"ğŸ¤–\"\n",
    "    content_preview = msg['content'][:100] + \"...\" if len(msg['content']) > 100 else msg['content']\n",
    "    print(f\"{i}. {role_icon} [{msg['role']}]: {content_preview}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac411fa6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Expose Agent as FastAPI Endpoint\n",
    "\n",
    "Now let's create a FastAPI application to expose our LangChain agent as an API with short-term memory connected by user_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d4219b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… FastAPI application code generated!\n",
      "   Save this to: app/api/tools/langchain_agent.py\n",
      "\n",
      "ğŸ“ API Endpoints:\n",
      "   POST /chat           - Chat with the agent\n",
      "   GET  /sessions/{user_id} - Get user's sessions\n",
      "   GET  /sessions/{session_id}/messages - Get session messages\n",
      "   DELETE /sessions/{session_id} - Delete a session\n",
      "\n",
      "ğŸš€ Run with: uvicorn langchain_agent:app --reload --port 8001\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# FASTAPI APPLICATION CODE\n",
    "# =============================================================================\n",
    "# This code would be saved to a file like: app/api/tools/langchain_agent.py\n",
    "\n",
    "FASTAPI_CODE = '''\n",
    "\"\"\"\n",
    "LangChain Agent API with MongoDB Short-Term Memory\n",
    "\n",
    "This module exposes a LangChain ReAct agent with:\n",
    "- All existing tools (semantic search, expert finder, jargon buster, etc.)\n",
    "- MongoDB-based short-term memory connected by user_id\n",
    "- Session management with 24-hour TTL\n",
    "\n",
    "Usage:\n",
    "    POST /chat\n",
    "    {\n",
    "        \"message\": \"What does API mean?\",\n",
    "        \"user_id\": \"user-123\"\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import uuid\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Optional, List\n",
    "\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from pydantic import BaseModel, Field\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Add parent directories to path\n",
    "sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n",
    "\n",
    "from pymongo import MongoClient, ASCENDING, DESCENDING\n",
    "from langchain_core.tools import StructuredTool\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_groq import ChatGroq\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# Import existing tool functions\n",
    "from core.data_tools import search_vector_db, find_users\n",
    "from core.expert_tools import find_experts_tool\n",
    "from core.jargon_tools import jargon_buster_tool\n",
    "from core.summarizer_tools import summarize_tool\n",
    "from core.meeting_tools import schedule_meeting_tool\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "MONGO_URI = os.getenv(\"MONGO_URI\")\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "DATABASE_NAME = \"connectbest_chat\"\n",
    "AGENT_MEMORY_COLLECTION = \"agent_conversations\"\n",
    "SESSION_TTL_HOURS = 24\n",
    "\n",
    "# =============================================================================\n",
    "# AGENT SYSTEM PROMPT\n",
    "# =============================================================================\n",
    "\n",
    "AGENT_SYSTEM_MESSAGE = \"\"\"You are ConnectBest AI, a helpful Slack assistant for enterprise teams.\n",
    "\n",
    "You have access to tools to help users:\n",
    "1. **semantic_search** - Search past Slack messages by topic\n",
    "2. **find_experts** - Find people who know about specific topics\n",
    "3. **explain_jargon** - Explain company jargon, acronyms, and technical terms\n",
    "4. **summarize_channel** - Summarize channel conversations  \n",
    "5. **schedule_zoom_meeting** - Schedule Zoom meetings with colleagues\n",
    "6. **find_user_info** - Look up information about colleagues\n",
    "\n",
    "Guidelines:\n",
    "- Be concise and helpful\n",
    "- Use tools when appropriate - don't guess at information\n",
    "- Reference conversation history to understand context\n",
    "- Format responses nicely with markdown when appropriate\n",
    "- If you can't help with something, explain why\"\"\"\n",
    "\n",
    "# =============================================================================\n",
    "# CREATE LANGCHAIN TOOLS\n",
    "# =============================================================================\n",
    "\n",
    "def create_langchain_tools() -> List[StructuredTool]:\n",
    "    \"\"\"Create LangChain StructuredTool wrappers for existing functions\"\"\"\n",
    "    \n",
    "    # 1. Semantic Search Tool\n",
    "    def semantic_search_wrapper(query: str, channel_id: str = \"\", limit: int = 10):\n",
    "        \"\"\"Search Slack messages using semantic similarity\"\"\"\n",
    "        return search_vector_db(query, channel_id or None, limit)\n",
    "    \n",
    "    semantic_search = StructuredTool.from_function(\n",
    "        func=semantic_search_wrapper,\n",
    "        name=\"semantic_search\",\n",
    "        description=\"Search past Slack messages using semantic similarity. Use this to find relevant messages about a topic.\"\n",
    "    )\n",
    "    \n",
    "    # 2. Find Experts Tool\n",
    "    def find_experts_wrapper(topic: str, limit: int = 5):\n",
    "        \"\"\"Find experts on a topic\"\"\"\n",
    "        return find_experts_tool(topic, limit)\n",
    "    \n",
    "    find_experts = StructuredTool.from_function(\n",
    "        func=find_experts_wrapper,\n",
    "        name=\"find_experts\",\n",
    "        description=\"Find people who are experts on a specific topic based on their Slack messages.\"\n",
    "    )\n",
    "    \n",
    "    # 3. Jargon Buster Tool\n",
    "    def explain_jargon_wrapper(term: str):\n",
    "        \"\"\"Explain jargon or acronym\"\"\"\n",
    "        return jargon_buster_tool(term)\n",
    "    \n",
    "    explain_jargon = StructuredTool.from_function(\n",
    "        func=explain_jargon_wrapper,\n",
    "        name=\"explain_jargon\",\n",
    "        description=\"Explain a company jargon, acronym, or technical term. Use when users ask what something means.\"\n",
    "    )\n",
    "    \n",
    "    # 4. Summarize Channel Tool\n",
    "    def summarize_channel_wrapper(channel_id: str, days: int = 7):\n",
    "        \"\"\"Summarize channel conversations\"\"\"\n",
    "        return summarize_tool(channel_id, days)\n",
    "    \n",
    "    summarize_channel = StructuredTool.from_function(\n",
    "        func=summarize_channel_wrapper,\n",
    "        name=\"summarize_channel\",\n",
    "        description=\"Summarize recent conversations in a Slack channel.\"\n",
    "    )\n",
    "    \n",
    "    # 5. Schedule Meeting Tool\n",
    "    def schedule_meeting_wrapper(\n",
    "        topic: str,\n",
    "        date: str,\n",
    "        time: str,\n",
    "        duration_minutes: int = 30,\n",
    "        attendee_emails: str = \"\"\n",
    "    ):\n",
    "        \"\"\"Schedule a Zoom meeting\"\"\"\n",
    "        emails = [e.strip() for e in attendee_emails.split(\",\") if e.strip()]\n",
    "        return schedule_meeting_tool(topic, date, time, duration_minutes, emails)\n",
    "    \n",
    "    schedule_zoom_meeting = StructuredTool.from_function(\n",
    "        func=schedule_meeting_wrapper,\n",
    "        name=\"schedule_zoom_meeting\",\n",
    "        description=\"Schedule a Zoom meeting. Provide topic, date (YYYY-MM-DD), time (HH:MM), duration in minutes, and comma-separated attendee emails.\"\n",
    "    )\n",
    "    \n",
    "    # 6. Find User Info Tool\n",
    "    def find_user_wrapper(name: str):\n",
    "        \"\"\"Find user information\"\"\"\n",
    "        return find_users(name, 1)\n",
    "    \n",
    "    find_user_info = StructuredTool.from_function(\n",
    "        func=find_user_wrapper,\n",
    "        name=\"find_user_info\",\n",
    "        description=\"Look up information about a colleague by name.\"\n",
    "    )\n",
    "    \n",
    "    return [\n",
    "        semantic_search,\n",
    "        find_experts,\n",
    "        explain_jargon,\n",
    "        summarize_channel,\n",
    "        schedule_zoom_meeting,\n",
    "        find_user_info\n",
    "    ]\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# MONGODB MEMORY MANAGER\n",
    "# =============================================================================\n",
    "\n",
    "class MemoryManager:\n",
    "    \"\"\"Manages conversation memory in MongoDB\"\"\"\n",
    "    \n",
    "    def __init__(self, mongo_uri: str, database_name: str):\n",
    "        self.client = MongoClient(mongo_uri)\n",
    "        self.db = self.client[database_name]\n",
    "        self.collection = self.db[AGENT_MEMORY_COLLECTION]\n",
    "        \n",
    "        # Create TTL index for automatic cleanup\n",
    "        self.collection.create_index(\n",
    "            \"created_at\",\n",
    "            expireAfterSeconds=SESSION_TTL_HOURS * 3600\n",
    "        )\n",
    "    \n",
    "    def get_or_create_session(self, user_id: str) -> str:\n",
    "        \"\"\"Get existing session or create new one for user\"\"\"\n",
    "        cutoff = datetime.now() - timedelta(hours=SESSION_TTL_HOURS)\n",
    "        \n",
    "        existing = self.collection.find_one(\n",
    "            {\"user_id\": user_id, \"created_at\": {\"$gte\": cutoff}},\n",
    "            sort=[(\"created_at\", DESCENDING)]\n",
    "        )\n",
    "        \n",
    "        if existing:\n",
    "            return existing[\"session_id\"]\n",
    "        \n",
    "        session_id = str(uuid.uuid4())\n",
    "        self.collection.insert_one({\n",
    "            \"user_id\": user_id,\n",
    "            \"session_id\": session_id,\n",
    "            \"created_at\": datetime.now(),\n",
    "            \"messages\": []\n",
    "        })\n",
    "        return session_id\n",
    "    \n",
    "    def load_messages(self, session_id: str) -> List:\n",
    "        \"\"\"Load message history from session\"\"\"\n",
    "        session = self.collection.find_one({\"session_id\": session_id})\n",
    "        if not session:\n",
    "            return []\n",
    "        \n",
    "        messages = []\n",
    "        for msg in session.get(\"messages\", []):\n",
    "            if msg[\"role\"] == \"user\":\n",
    "                messages.append(HumanMessage(content=msg[\"content\"]))\n",
    "            else:\n",
    "                messages.append(AIMessage(content=msg[\"content\"]))\n",
    "        return messages\n",
    "    \n",
    "    def save_message(self, session_id: str, role: str, content: str):\n",
    "        \"\"\"Save a message to the session\"\"\"\n",
    "        self.collection.update_one(\n",
    "            {\"session_id\": session_id},\n",
    "            {\n",
    "                \"$push\": {\n",
    "                    \"messages\": {\n",
    "                        \"role\": role,\n",
    "                        \"content\": content,\n",
    "                        \"timestamp\": datetime.now()\n",
    "                    }\n",
    "                },\n",
    "                \"$set\": {\"updated_at\": datetime.now()}\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    def get_user_sessions(self, user_id: str) -> List[dict]:\n",
    "        \"\"\"Get all sessions for a user\"\"\"\n",
    "        sessions = list(self.collection.find(\n",
    "            {\"user_id\": user_id},\n",
    "            {\"_id\": 0, \"session_id\": 1, \"created_at\": 1, \"messages\": 1}\n",
    "        ).sort(\"created_at\", DESCENDING))\n",
    "        return sessions\n",
    "    \n",
    "    def clear_session(self, session_id: str):\n",
    "        \"\"\"Delete a specific session\"\"\"\n",
    "        self.collection.delete_one({\"session_id\": session_id})\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# FASTAPI APPLICATION\n",
    "# =============================================================================\n",
    "\n",
    "app = FastAPI(\n",
    "    title=\"ConnectBest AI Agent API\",\n",
    "    description=\"LangChain Agent with MongoDB Memory\",\n",
    "    version=\"1.0.0\"\n",
    ")\n",
    "\n",
    "# CORS middleware\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "\n",
    "# Initialize components\n",
    "memory_manager = MemoryManager(MONGO_URI, DATABASE_NAME)\n",
    "all_tools = create_langchain_tools()\n",
    "llm = ChatGroq(\n",
    "    api_key=GROQ_API_KEY,\n",
    "    model_name=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.3,\n",
    ")\n",
    "agent = create_react_agent(llm, all_tools, prompt=AGENT_SYSTEM_MESSAGE)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# REQUEST/RESPONSE MODELS\n",
    "# =============================================================================\n",
    "\n",
    "class ChatRequest(BaseModel):\n",
    "    message: str = Field(..., description=\"The user's message\")\n",
    "    user_id: str = Field(..., description=\"Unique user identifier\")\n",
    "    include_history: bool = Field(True, description=\"Whether to include conversation history\")\n",
    "\n",
    "class ChatResponse(BaseModel):\n",
    "    response: str\n",
    "    session_id: str\n",
    "    user_id: str\n",
    "    message_count: int\n",
    "\n",
    "class SessionInfo(BaseModel):\n",
    "    session_id: str\n",
    "    created_at: datetime\n",
    "    message_count: int\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# API ENDPOINTS\n",
    "# =============================================================================\n",
    "\n",
    "@app.get(\"/health\")\n",
    "async def health_check():\n",
    "    \"\"\"Health check endpoint\"\"\"\n",
    "    return {\"status\": \"healthy\", \"service\": \"langchain-agent\"}\n",
    "\n",
    "\n",
    "@app.post(\"/chat\", response_model=ChatResponse)\n",
    "async def chat(request: ChatRequest):\n",
    "    \"\"\"\n",
    "    Chat with the AI agent.\n",
    "    \n",
    "    The agent has access to:\n",
    "    - semantic_search: Search past Slack messages\n",
    "    - find_experts: Find topic experts\n",
    "    - explain_jargon: Explain acronyms and terms\n",
    "    - summarize_channel: Summarize channel conversations\n",
    "    - schedule_zoom_meeting: Schedule meetings\n",
    "    - find_user_info: Look up colleagues\n",
    "    \n",
    "    Conversation history is automatically maintained per user_id.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get or create session\n",
    "        session_id = memory_manager.get_or_create_session(request.user_id)\n",
    "        \n",
    "        # Load previous messages\n",
    "        previous_messages = []\n",
    "        if request.include_history:\n",
    "            previous_messages = memory_manager.load_messages(session_id)\n",
    "        \n",
    "        # Build message list\n",
    "        messages = [SystemMessage(content=AGENT_SYSTEM_MESSAGE)]\n",
    "        messages.extend(previous_messages)\n",
    "        messages.append(HumanMessage(content=request.message))\n",
    "        \n",
    "        # Run agent\n",
    "        config = {\"configurable\": {\"thread_id\": session_id}}\n",
    "        result = await agent.ainvoke({\"messages\": messages}, config=config)\n",
    "        \n",
    "        # Extract response\n",
    "        final_message = result[\"messages\"][-1]\n",
    "        response_content = final_message.content\n",
    "        \n",
    "        # Save to memory\n",
    "        memory_manager.save_message(session_id, \"user\", request.message)\n",
    "        memory_manager.save_message(session_id, \"assistant\", response_content)\n",
    "        \n",
    "        # Get message count\n",
    "        session = memory_manager.collection.find_one({\"session_id\": session_id})\n",
    "        message_count = len(session.get(\"messages\", []))\n",
    "        \n",
    "        return ChatResponse(\n",
    "            response=response_content,\n",
    "            session_id=session_id,\n",
    "            user_id=request.user_id,\n",
    "            message_count=message_count\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "\n",
    "\n",
    "@app.get(\"/sessions/{user_id}\", response_model=List[SessionInfo])\n",
    "async def get_user_sessions(user_id: str):\n",
    "    \"\"\"Get all sessions for a user\"\"\"\n",
    "    sessions = memory_manager.get_user_sessions(user_id)\n",
    "    return [\n",
    "        SessionInfo(\n",
    "            session_id=s[\"session_id\"],\n",
    "            created_at=s[\"created_at\"],\n",
    "            message_count=len(s.get(\"messages\", []))\n",
    "        )\n",
    "        for s in sessions\n",
    "    ]\n",
    "\n",
    "\n",
    "@app.delete(\"/sessions/{session_id}\")\n",
    "async def delete_session(session_id: str):\n",
    "    \"\"\"Delete a specific session\"\"\"\n",
    "    memory_manager.clear_session(session_id)\n",
    "    return {\"status\": \"deleted\", \"session_id\": session_id}\n",
    "\n",
    "\n",
    "@app.get(\"/sessions/{session_id}/messages\")\n",
    "async def get_session_messages(session_id: str):\n",
    "    \"\"\"Get all messages in a session\"\"\"\n",
    "    messages = memory_manager.load_messages(session_id)\n",
    "    return {\n",
    "        \"session_id\": session_id,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\" if isinstance(m, HumanMessage) else \"assistant\", \"content\": m.content}\n",
    "            for m in messages\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# RUN SERVER\n",
    "# =============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import uvicorn\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8001)\n",
    "'''\n",
    "\n",
    "print(\"âœ… FastAPI application code generated!\")\n",
    "print(\"   Save this to: app/api/tools/langchain_agent.py\")\n",
    "print()\n",
    "print(\"ğŸ“ API Endpoints:\")\n",
    "print(\"   POST /chat           - Chat with the agent\")\n",
    "print(\"   GET  /sessions/{user_id} - Get user's sessions\")\n",
    "print(\"   GET  /sessions/{session_id}/messages - Get session messages\")\n",
    "print(\"   DELETE /sessions/{session_id} - Delete a session\")\n",
    "print()\n",
    "print(\"ğŸš€ Run with: uvicorn langchain_agent:app --reload --port 8001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05308e2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "We've successfully built a complete LangChain agent with MongoDB short-term memory! Here's what was implemented:\n",
    "\n",
    "### ğŸ§  Memory Features\n",
    "- **Short-term memory** connected by `user_id`\n",
    "- **Session management** with 24-hour TTL (auto-cleanup via MongoDB TTL index)\n",
    "- **Message history** persisted in `agent_conversations` collection\n",
    "- **Context awareness** - agent remembers previous messages in conversation\n",
    "\n",
    "### ğŸ› ï¸ Tools Available\n",
    "1. `semantic_search` - Search past Slack messages by topic\n",
    "2. `find_experts` - Find topic experts based on message history  \n",
    "3. `explain_jargon` - Explain company acronyms and technical terms\n",
    "4. `summarize_channel` - Summarize channel conversations\n",
    "5. `schedule_zoom_meeting` - Schedule Zoom meetings\n",
    "6. `find_user_info` - Look up colleague information\n",
    "\n",
    "### ğŸ“¡ API Endpoints\n",
    "| Method | Endpoint | Description |\n",
    "|--------|----------|-------------|\n",
    "| POST | `/chat` | Chat with the agent |\n",
    "| GET | `/sessions/{user_id}` | Get user's sessions |\n",
    "| GET | `/sessions/{session_id}/messages` | Get session messages |\n",
    "| DELETE | `/sessions/{session_id}` | Delete a session |\n",
    "\n",
    "### ğŸš€ Running the API\n",
    "```bash\n",
    "cd app/api/tools\n",
    "uvicorn langchain_agent:app --reload --port 8001\n",
    "```\n",
    "\n",
    "### ğŸ“¦ Files Created\n",
    "- `app/api/tools/langchain_agent.py` - FastAPI application with LangChain agent"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
